{
  "items": [
    {
      "description": "Contributions are greatly welcomed! Please refer to Contribution Guidelines before taking any actions.\n",
      "items": [],
      "title": "Contributing"
    },
    {
      "description": "",
      "items": [],
      "title": "Papers"
    },
    {
      "description": "",
      "items": [],
      "title": "Abduction"
    },
    {
      "description": "",
      "items": [],
      "title": "Bayesian Modeling"
    },
    {
      "description": "",
      "items": [
        {
          "children": [],
          "description": "2022. This tutorial on generative modeling is in part of Statistical Machine Learning Tutorial by Ying Nian Wu at UCLA Statistics. The tutorial goes over the key equations and algorithms for learning recent generative models, including energy-based models, diffusion/score-based models, autoregressive/flow-based models, VAEs, and GANs, and explains the connections between these models.",
          "title": "Generative Modeling Explained",
          "repo_info": {
            "archived": false,
            "language": null,
            "last_commit": "2023-01-07T07:17:12Z",
            "owner": "YuzheSHI",
            "repo": "generative-modeling-explained",
            "stars": 64
          }
        },
        {
          "children": [],
          "description": "1995. []. Don Rubin's introductory book on Bayesian models.",
          "title": "Bayesian Data Analysis"
        },
        {
          "children": [],
          "description": "1998. []. []. This article presents a statistical theory for texture modeling. This theory combines filtering theory and Markov random field modeling through the maximum entropy principle, and interprets and clarifies many previous concepts and methods for texture analysis and synthesis from a unified point of view. The theory characterizes the ensemble of images I with the same texture appearance by a probability distribution f(I) on a random field, and the objective of texture modeling is to make inference about f(I), given a set of observed texture examples.",
          "title": "Filters, random fields and maximum entropy (FRAME): Towards a unified theory for texture modeling"
        },
        {
          "children": [],
          "description": "2004. []. []. We perceive the shapes and material properties of objects quickly and reliably despite the complexity and objective ambiguities of natural images. Typical images are highly complex because they consist of many objects embedded in background clutter. Moreover, the image features of an object are extremely variable and ambiguous owing to the effects of projection, occlusion, background clutter, and illumination. The very success of everyday vision implies neural mechanisms, yet to be understood, that discount irrelevant information and organize ambiguous or noisy local image features into objects and surfaces. Recent work in Bayesian theories of visual perception has shown how complexity may be managed and ambiguity resolved through the task-dependent, probabilistic integration of prior object knowledge with image features.",
          "title": "Object Perception as Bayesian Inference"
        },
        {
          "children": [],
          "description": "2018. []. []. The pattern theory of Grenander is a mathematical framework where patterns are represented by probability models on random variables of algebraic structures. In this paper, the authors review three families of probability models, namely, the discriminative models, the descriptive models, and the generative models. A discriminative model is in the form of a classifier. It specifies the conditional probability of the class label given the input signal. A descriptive model specifies the probability distribution of the signal, based on an energy function defined on the signal. A generative model assumes that the signal is generated by some latent variables via a transformation. The authors shall review these models within a common framework and explore their connections, and shall also review the recent developments that take advantage of the high approximation capacities of deep neural networks.",
          "title": "A tale of three probabilistic families: Discriminative, descriptive, and generative models"
        },
        {
          "children": [],
          "description": "2008. []. [].  One fundamental property of natural image data that distinguishes vision from other sensory tasks such as speech recognition is that scale plays a profound role in image formation and interpretation. Specifically, visual objects can appear at a wide range of scales in the images due to the change of viewing distance as well as camera resolution. The same objects appearing at different scales produce different image data with different statistical properties. In particular, this work shows that the entropy rate of the image data changes over scale. Moreover, the inferential uncertainty changes over scale too. The authors call these changes information scaling. They then examine both empirically and theoretically two prominent and yet largely isolated classes of image models, namely, wavelet sparse coding models and Markov random field models. The results indicate that the two classes of models are appropriate for two different entropy regimes: sparse coding targets low entropy regimes, whereas Markov random fields are appropriate for high entropy regimes. Because information scaling connects different entropy regimes, both sparse coding and Markov random fields are necessary for representing natural image data, and information scaling triggers transitions between these two regimes.",
          "title": "From information scaling of natural images to regimes of statistical models"
        },
        {
          "children": [],
          "description": "2016. []. The authors show that a generative random field model, which they call generative ConvNet, can be derived from the commonly used discriminative ConvNet, by assuming a ConvNet for multi-category classification and assuming one of the category is a base category generated by a reference distribution. For a further assumption that the non-linearity in the ConvNet is Rectified Linear Unit (ReLU) and the reference distribution is Gaussian white noise, then a generative ConvNet model that is unique among energy-based models is obtained: The model is piecewise Gaussian, and the means of the Gaussian pieces are defined by an auto-encoder, where the filters in the bottom-up encoding become the basis functions in the top-down decoding, and the binary activation variables detected by the filters in the bottom-up convolution process become the coefficients of the basis functions in the top-down deconvolution process.",
          "title": "A Theory of Generative ConvNet"
        },
        {
          "children": [],
          "description": "2018. []. This paper studies the cooperative training of two generative models for image modeling and synthesis. Both models are parametrized by convolutional neural networks (ConvNets). The first model is a deep energy-based model, whose energy function is defined by a bottom-up ConvNet, which maps the observed image to the energy. We call it the descriptor network. The second model is a generator network, which is a non-linear version of factor analysis. It is defined by a top-down ConvNet, which maps the latent factors to the observed image. The maximum likelihood learning algorithms of both models involve MCMC sampling such as Langevin dynamics. This work observes that the two learning algorithms can be seamlessly interwoven into a cooperative learning algorithm that can train both models simultaneously. Specifically, within each iteration of the cooperative learning algorithm, the generator model generates initial synthesized examples to initialize a finite-step MCMC that samples and trains the energy-based descriptor model. After that, the generator model learns from how the MCMC changes its synthesized examples. That is, the descriptor model teaches the generator model by MCMC, so that the generator model accumulates the MCMC transitions and reproduces them by direct ancestral sampling.",
          "title": "Cooperative Training of Descriptor and Generator Networks"
        },
        {
          "children": [],
          "description": "2020. []. []. []. A milestone paper on Latent Energy-Based Model.",
          "title": "Learning Latent Space Energy-Based Prior Model",
          "repo_info": {
            "archived": false,
            "language": "Python",
            "last_commit": "2020-10-20T11:40:41Z",
            "owner": "bpucla",
            "repo": "latent-space-EBM-prior",
            "stars": 37
          }
        },
        {
          "children": [],
          "description": "2021. []. [].",
          "title": "Learning Energy-Based Models by Diffusion Recovery Likelihood",
          "repo_info": {
            "archived": false,
            "language": "Python",
            "last_commit": "2021-03-17T07:34:49Z",
            "owner": "ruiqigao",
            "repo": "recovery_likelihood",
            "stars": 53
          }
        },
        {
          "children": [],
          "description": "2021. [].",
          "title": "Score-Based Generative Modeling through Stochastic Differential Equations"
        },
        {
          "children": [],
          "description": "2020. [].",
          "title": "Latent Space Factorisation and Manipulation via Matrix Subspace Projection"
        },
        {
          "children": [],
          "description": "1997. []. []. This article proposes a general theory and methodology, called the minimax entropy principle, for building statistical models for images (or signals) in a variety of applications. This principle consists of two parts. The first is the maximum entropy principle for feature binding (or fusion): for a given set of observed feature statistics, a distribution can be built to bind these feature statistics together by maximizing the entropy over all distributions that reproduce them. The second part is the minimum entropy principle for feature selection: among all plausible sets of feature statistics, we choose the set whose maximum entropy distribution has the minimum entropy. Computational and inferential issues in both parts are addressed; in particular, a feature pursuit procedure is proposed for approximately selecting the optimal set of features. The minimax entropy principle is then corrected by considering the sample variation in the observed feature statistics, and an information criterion for feature pursuit is derived. The minimax entropy principle is applied to texture modeling, where a novel Markov random field (MRF) model, called FRAME (filter, random field, and minimax entropy), is derived, and encouraging results are obtained in experiments on a variety of texture images.",
          "title": "Minimax entropy principle and its application to texture modeling"
        },
        {
          "children": [],
          "description": "1999. []. []. Viewing the observed data of a statistical model as incomplete and augmenting its missing parts are useful for clarifying concepts and central to the invention of two well-known statistical algorithms: expectation-maximization (EM) and data augmentation. Recently, the authors demonstrated that expanding the parameter space along with augmenting the missing data is useful for accelerating iterative computation in an EM algorithm. The main purpose of this article is to rigorously define a parameter expanded data augmentation (PX-DA) algorithm and to study its theoretical properties. The PX-DA is a special way of using auxiliary variables to accelerate Gibbs sampling algorithms and is closely related to reparameterization techniques.",
          "title": "Parameter Expansion for Data Augmentation"
        },
        {
          "children": [],
          "description": "2002. []. []. This paper presents a computational paradigm called Data-Driven Markov Chain Monte Carlo (DDMCMC) for image segmentation in the Bayesian statistical framework. The paper contributes to image segmentation in four aspects. First, it designs efficient and well-balanced Markov Chain dynamics to explore the complex solution space and, thus, achieves a nearly global optimal solution independent of initial segmentations. Second, it presents a mathematical principle and a K-adventurers algorithm for computing multiple distinct solutions from the Markov chain sequence and, thus, it incorporates intrinsic ambiguities in image segmentation. Third, it utilizes data-driven (bottom-up) techniques, such as clustering and edge detection, to compute importance proposal probabilities, which drive the Markov chain dynamics and achieve tremendous speedup in comparison to the traditional jump-diffusion methods. Fourth, the DDMCMC paradigm provides a unifying framework in which the role of many existing segmentation algorithms, such as, edge detection, clustering, region growing, split-merge, snake/balloon, and region competition, are revealed as either realizing Markov chain dynamics or computing importance proposal probabilities. Thus, the DDMCMC paradigm combines and generalizes these segmentation methods in a principled way.",
          "title": "Image segmentation by data-driven markov chain monte carlo"
        },
        {
          "children": [],
          "description": "2006. [].",
          "title": "Efficient Learning of Sparse Representations with an Energy-Based Model"
        },
        {
          "children": [],
          "description": "2006. []. Yann LeCun's tutorial on energy-based learning.",
          "title": "A Tutorial on Energy-Based Learning"
        },
        {
          "children": [],
          "description": "2016. [].",
          "title": "Unsupervised Representaton Learning with Deep Convolutional Generative Adversarial Networks"
        },
        {
          "children": [],
          "description": "2019. []. This paper provides new insights on the Unadjusted Langevin Algorithm. The authors show that this method can be formulated as the first order optimization algorithm for an objective functional defined on the Wasserstein space of order $2$. Using this interpretation and techniques borrowed from convex optimization, the authors give a non-asymptotic analysis of this method to sample from log-concave smooth target distribution on $\\mathbb{R}^d$. Based on this interpretation, the authors propose two new methods for sampling from a non-smooth target distribution. These new algorithms are natural extensions of the Stochastic Gradient Langevin Dynamics (SGLD) algorithm, which is a popular extension of the Unadjusted Langevin Algorithm for largescale Bayesian inference. Using the optimization perspective, the authors provide non-asymptotic convergence analysis for the newly proposed methods.",
          "title": "Analysis of Langevin Monte Carlo via Convex Optimization"
        },
        {
          "children": [],
          "description": "2017. []. []. Learning from a few examples and generalizing to markedly different situations are capabilities of human visual intelligence that are yet to be matched by leading machine learning models. By drawing inspiration from systems neuroscience, this work introduces a probabilistic generative model for vision in which message-passing–based inference handles recognition, segmentation, and reasoning in a unified way. The model demonstrates excellent generalization and occlusion-reasoning capabilities and outperforms deep neural networks on a challenging scene text recognition benchmark while being 300-fold more data efficient. In addition, the model fundamentally breaks the defense of modern text-based CAPTCHAs (Completely Automated Public Turing test to tell Computers and Humans Apart) by generatively segmenting characters without CAPTCHA-specific heuristics.",
          "title": "A generative vision model that trains with high data efficiency and breaks text-based CAPTCHAs"
        },
        {
          "children": [],
          "description": "2017. []. []. Why are human inferences sometimes remarkably close to the Bayesian ideal and other times systematically biased? In particular, why do humans make near-rational inferences in some natural domains where the candidate hypotheses are explicitly available, whereas tasks in similar domains requiring the self-generation of hypotheses produce systematic deviations from rational inference. This work proposes that these deviations arise from algorithmic processes approximating Bayes’ rule. Specifically in our account, hypotheses are generated stochastically from a sampling process, such that the sampled hypotheses form a Monte Carlo approximation of the posterior.",
          "title": "Where do hypotheses come from?"
        }
      ],
      "title": "Generative Model"
    },
    {
      "description": "",
      "items": [],
      "title": "Concepts"
    },
    {
      "description": "",
      "items": [
        {
          "children": [],
          "description": "2023. []. []. []. []. []. []. Mapping molecular structure to odor perception is a key challenge in olfaction. This work used graph neural networks to generate a principal odor map (POM) that preserves perceptual relationships and enables odor quality prediction for previously uncharacterized odorants. The model was as reliable as a human in describing odor quality: On a prospective validation set of 400 out-of-sample odorants, the model-generated odor profile more closely matched the trained panel mean than did the median panelist. By applying simple, interpretable, theoretically rooted transformations, the POM outperformed chemoinformatic models on several other odor prediction tasks, indicating that the POM successfully encoded a generalized map of structure-odor relationships. This approach broadly enables odor prediction and paves the way toward digitizing odors.",
          "title": "A principal odor map unifies diverse tasks in olfactory perception",
          "repo_info": {
            "archived": false,
            "language": "Jupyter Notebook",
            "last_commit": "2023-08-31T16:00:39Z",
            "owner": "osmoai",
            "repo": "publications",
            "stars": 29
          }
        },
        {
          "children": [],
          "description": "2023. []. []. Odorous compounds with similar POM representations are more likely to co-occur within a substance and be metabolically closely related; metabolic reaction sequences also follow smooth paths in POM despite large jumps in molecular structure.",
          "title": "Metabolic activity organizes olfactory representations",
          "repo_info": {
            "archived": false,
            "language": "Jupyter Notebook",
            "last_commit": "2023-08-31T16:00:39Z",
            "owner": "osmoai",
            "repo": "publications",
            "stars": 29
          }
        },
        {
          "children": [],
          "description": "2020. []. []. Tactile sensing is a key sensor modality for robots interacting with their surroundings. These sensors provide a rich and diverse set of data signals that contain detailed information collected from contacts between the robot and its environment. The data are however not limited to individual contacts and can be used to extract a wide range of information about the objects in the environment as well as the actions of the robot during the interactions. This article provides an overview of tactile information and its applications in robotics. The authors present a hierarchy consisting of raw, contact, object, and action levels to structure the tactile information, with higher-level information often building upon lower-level information. The authors discuss different types of information that can be extracted at each level of the hierarchy. The article also includes an overview of different types of robot applications and the types of tactile information that they employ. Finally the article ends with a discussion for future tactile applications which are still beyond the current capabilities of robots.",
          "title": "A Review of Tactile Information: Perception and Action Through Touch"
        },
        {
          "children": [],
          "description": "2023. []. []. This work presents ImageBind, an approach to learn a joint embedding across six different modalities - images, text, audio, depth, thermal, and IMU data. The authors show that all combinations of paired data are not necessary to train such a joint embedding, and only image-paired data is sufficient to bind the modalities together. ImageBind can leverage recent large scale vision-language models, and extends their zero-shot capabilities to new modalities just by using their natural pairing with images. It enables novel emergent applications 'out-of-the-box' including cross-modal retrieval, composing modalities with arithmetic, cross-modal detection and generation. The emergent capabilities improve with the strength of the image encoder and this work sets a new state-of-the-art on emergent zero-shot recognition tasks across modalities, outperforming specialist supervised models. Finally, the authors show strong few-shot recognition results outperforming prior work, and that ImageBind serves as a new way to evaluate vision models for visual and non-visual tasks.",
          "title": "ImageBind: One Embedding Space To Bind Them All",
          "repo_info": {
            "archived": false,
            "language": "Python",
            "last_commit": "2025-11-21T21:48:14Z",
            "owner": "facebookresearch",
            "repo": "ImageBind",
            "stars": 8969
          }
        },
        {
          "children": [],
          "description": "2022. []. Semantic features have been playing a central role in investigating the nature of our conceptual representations. Yet the enormous time and effort required to empirically sample and norm features from human raters has restricted their use to a limited set of manually curated concepts. Given recent promising developments with transformer-based language models, here the authors asked whether it was possible to use such models to automatically generate meaningful lists of properties for arbitrary object concepts and whether these models would produce features similar to those found in humans. To this end, the authors probed a GPT-3 model to generate semantic features for 1,854 objects and compared automatically-generated features to existing human feature norms. GPT-3 generated many more features than humans, yet showed a similar distribution in the types of generated features. Generated feature norms rivaled human norms in predicting similarity, relatedness, and category membership, while variance partitioning demonstrated that these predictions were driven by similar variance in humans and GPT-3. Together, these results highlight the potential of large language models to capture important facets of human knowledge and yield a new approach for automatically generating interpretable feature sets, thus drastically expanding the potential use of semantic features in psychological and linguistic studies.",
          "title": "Semantic features of object concepts generated with GPT-3"
        },
        {
          "children": [],
          "description": "2019. []. []. Humans perceive the world using multi-modal sensory inputs such as vision, audition, and touch. This work investigates the cross-modal connection between vision and touch. The main challenge in this cross-domain modeling task lies in the significant scale discrepancy between the two: while our eyes perceive an entire visual scene at once, humans can only feel a small region of an object at any given moment. To connect vision and touch, this work introduces new tasks of synthesizing plausible tactile signals from visual inputs as well as imagining how we interact with objects given tactile data as input. To accomplish the goals, the authors first equip robots with both visual and tactile sensors and collect a large-scale dataset of corresponding vision and tactile image sequences. To close the scale gap, the authors present a new conditional adversarial model that incorporates the scale and location information of the touch. Human perceptual studies demonstrate that the model can produce realistic visual images from tactile data and vice versa.",
          "title": "Connecting Touch and Vision via Cross-Modal Prediction",
          "repo_info": {
            "archived": false,
            "language": "Python",
            "last_commit": "2019-06-17T06:17:49Z",
            "owner": "YunzhuLi",
            "repo": "VisGel",
            "stars": 75
          }
        },
        {
          "children": [],
          "description": "2022. []. Testing the concept representation by neural networks through Fodor's theory of concepts.",
          "title": "Unit Testing for Concepts in Neural Networks"
        },
        {
          "children": [],
          "description": "2024. []. A preliminary work empirically showing that the intermediate embeddings of multilingual Transformers (1) start far away from output token embeddings; (2) already allow for decoding a semantically correct next token in the middle layers, but give higher probability to its version in English than in the input language; (3) finally move into an input-language-specific region of the embedding space. Also, the embedding of abstract concept space lies closer to English than to other languages.",
          "title": "Do Llamas Work in English? On the Latent Language of Multilingual Transformers"
        },
        {
          "children": [],
          "description": "2024. []. []. In what sense does a large language model (LLM) have knowledge? The authors answer by granting LLMs ‘instrumental knowledge’: knowledge gained by using next-word generation as an instrument. The authors then ask how instrumental knowledge is related to the ordinary, ‘worldly knowledge’ exhibited by humans, and explore this question in terms of the degree to which instrumental knowledge can be said to incorporate the structured world models of cognitive science. The authors discuss ways LLMs could recover degrees of worldly knowledge and suggest that such recovery will be governed by an implicit, resource-rational tradeoff between world models and tasks. The authors' answer to this question extends beyond the capabilities of a particular AI system and challenges assumptions about the nature of knowledge and intelligence.",
          "title": "From task structures to world models: what do LLMs know?"
        }
      ],
      "title": "AI Concept Representation"
    },
    {
      "description": "",
      "items": [],
      "title": "Complexity & Information Theory"
    },
    {
      "description": "",
      "items": [],
      "title": "Communications"
    },
    {
      "description": "",
      "items": [],
      "title": "Domain Specific Language"
    },
    {
      "description": "",
      "items": [
        {
          "children": [],
          "description": "2010. []. []. Biological Pathway Exchange (BioPAX) is a standard language to represent biological pathways at the molecular and cellular level and to facilitate the exchange of pathway data. BioPAX can represent metabolic and signaling pathways, molecular and genetic interactions and gene regulation networks.",
          "title": "The BioPAX community standard for pathway data sharing"
        },
        {
          "children": [],
          "description": "2021. []. The ability for viruses to mutate and evade the human immune system and cause infection, called viral escape, remains an obstacle to antiviral and vaccine development. Understanding the complex rules that govern escape could inform therapeutic design. This work modeled viral escape with machine learning algorithms originally developed for human natural language. The authors identified escape mutations as those that preserve viral infectivity but cause a virus to look different to the immune system, akin to word changes that preserve a sentence’s grammaticality but change its meaning. With this approach, language models of influenza hemagglutinin, HIV-1 envelope glycoprotein (HIV Env), and severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) Spike viral proteins can accurately predict structural escape patterns using sequence data alone. This study represents a promising conceptual bridge between natural language and viral evolution.",
          "title": "Learning the language of viral evolution and escape"
        },
        {
          "children": [],
          "description": "2022. []. Combining a basic set of building blocks into more complex forms is a universal design principle. Most protein designs have proceeded from a manual bottom-up approach using parts created by nature, but top-down design of proteins is fundamentally hard due to biological complexity. This work demonstrates how the modularity and programmability long sought for protein design can be realized through generative artificial intelligence. Advanced protein language models demonstrate emergent learning of atomic resolution structure and protein design principles. The authors leverage these developments to enable the programmable design of de novo protein sequences and structures of high complexity. First, the authors describe a high-level programming language based on modular building blocks that allows a designer to easily compose a set of desired properties. The authors then develop an energy-based generative model, built on atomic resolution structure prediction with a language model, that realizes all-atom structure designs that have the programmed properties. Designing a diverse set of specifications, including constraints on atomic coordinates, secondary structure, symmetry, and multimerization, demonstrates the generality and controllability of the approach. Enumerating constraints at increasing levels of hierarchical complexity shows that the approach can access a combinatorially large design space.",
          "title": "A high-level programming language for generative protein design"
        },
        {
          "children": [],
          "description": "2023. []. []. Advances in machine learning (ML) and automated experimentation are poised to vastly accelerate research in polymer science. Data representation is a critical aspect for enabling ML integration in research workflows, yet many data models impose significant rigidity making it difficult to accommodate a broad array of experiment and data types found in polymer science. This inflexibility presents a significant barrier for researchers to leverage their historical data in ML development. This work shows that a domain specific language, termed Chemical Markdown Language (CMDL), provides flexible, extensible, and consistent representation of disparate experiment types and polymer structures. CMDL enables seamless use of historical experimental data to fine-tune regression transformer (RT) models for generative molecular design tasks. The authors demonstrate the utility of this approach through the generation and the experimental validation of catalysts and polymers in the context of ring-opening polymerization---although the authors provide examples of how CMDL can be more broadly applied to other polymer classes. Critically, this work shows how the CMDL tuned model preserves key functional groups within the polymer structure, allowing for experimental validation. These results reveal the versatility of CMDL and how it facilitates translation of historical data into meaningful predictive and generative models to produce experimentally actionable output.",
          "title": "Artificial intelligence driven design of catalysts and materials for ring opening polymerization using a domain-specific language",
          "repo_info": {
            "archived": false,
            "language": "TypeScript",
            "last_commit": "2025-09-17T23:43:01Z",
            "owner": "IBM",
            "repo": "ibm-materials-notebook",
            "stars": 16
          }
        },
        {
          "children": [],
          "description": "It is now possible to model all or parts of legal agreements using code (smart contracts), decreasing the cost and friction of creating, securing, and generating binding legal agreements. Lawyers lack basic tools to build these dynamic, “smart” contracts in a way that is enforceable and understandable to a legal professional. OpenLaw is a technology stack to help power next generation \"smart\" legal agreements, with a domain-specific markup language, a integration framework, and a series of general applications.",
          "title": "OpenLaw"
        },
        {
          "children": [],
          "description": "2022. []. This paper proposes a domain-specific language, Scenic, for describing scenarios that are distributions over scenes and the behaviors of their agents over time. Scenic combines concise, readable syntax for spatiotemporal relationships with the ability to declaratively impose hard and soft constraints over the scenario.",
          "title": "Scenic: a language for scenario specification and data generation"
        },
        {
          "children": [],
          "description": "2020. []. []. This research addresses the understanding hardness raised from the conceptual discrepancy between contractual clauses and corresponding code of the Solidity programming language, by the design and study of a domain-specific smart contract language based on higher level of abstraction that can be automatically transformed to an implementation.",
          "title": "Domain Specific Language for Smart Contract Development"
        },
        {
          "children": [],
          "description": "2022. []. Smart contracts play a vital role in many fields. Despite being called smart, the development of smart contracts is a tedious task beyond defining a set of contractual rules. In addition to business knowledge, coding a smart contract requires strong technical knowledge in a multiplex of new and rapidly changing domain-specific languages and blockchain platforms. The goal of this paper is to assist developers in building smart contracts independently from the language or the target blockchain platform. In which, this paper presents the second-generation smart contract language iContractML 2.0. iContractML 2.0 is an extensible framework that empowers developers to model and generate functional smart contract code that can be deployed onto multiple blockchain platforms.",
          "title": "iContractML 2.0: A domain-specific language for modeling and deploying smart contracts onto multiple blockchain platforms"
        },
        {
          "children": [],
          "description": "2021. []. This work presents PClean, a probabilistic programming language (PPL) for leveraging dataset-specific knowledge to automate Bayesian cleaning, automating Bayesian approaches given the diversity of real-world error patterns and the hardness of inference.",
          "title": "PClean: Bayesian Data Cleaning at Scale with Domain-Specific Probabilistic Programming"
        },
        {
          "children": [],
          "description": "2021. []. []. This paper presents Omega, a probabilistic programming language with support for counterfactual inference. This feature is accomplished by introducing a new operator to probabilistic programming akin to Pearl’s do.",
          "title": "A Language for Counterfactual Generative Models",
          "repo_info": {
            "archived": false,
            "language": "Julia",
            "last_commit": "2025-10-21T15:27:18Z",
            "owner": "zenna",
            "repo": "Omega.jl",
            "stars": 177
          }
        },
        {
          "children": [],
          "description": "2011. []. []. This paper investigates the application of domain-specific languages in product line engineering (PLE). It starts by analyzing the limits of expressivity of feature models. Feature models correspond to context-free grammars without recursion, which prevents the expression of multiple instances and references. The authors then show how domain-specific languages (DSLs) can serve as a middle ground between feature modeling and programming. They can be used in cases where feature models are too limited, while keeping the separation between problem space and solution space provided by feature models. This work then categorizes useful combinations between configuration with feature model and construction with DSLs and provide an integration of DSLs into the conceptual framework of PLE. Finally the authors show how use of a consistent, unified formalism for models, code, and configuration can yield important benefits for managing variability and trace ability.",
          "title": "Product Line Engineering Using Domain-Specific Languages"
        },
        {
          "children": [],
          "description": "2021. []. This paper presents the design of the PPR-DSL to effectively and efficiently represent Product-Process-Resource (PPR) aspects and evaluate constraints defined for modeling PPR views in the Formalized Process Description standard (VDI 3682).",
          "title": "A Domain-Specific Language for Product-Process-Resource Modeling"
        },
        {
          "children": [],
          "description": "2018. []. []. This work proposes a systematic learning-based approach to the generation of massive quantities of synthetic 3D scenes and arbitrary numbers of photorealistic 2D images thereof, with associated ground truth information, for the purposes of training, benchmarking, and diagnosing learning-based computer vision and robotics algorithms. In particular, the authors devise a learning-based pipeline of algorithms capable of automatically generating and rendering a potentially infinite variety of indoor scenes by using a stochastic grammar, represented as an attributed Spatial And-Or Graph, in conjunction with state-of-the-art physics-based rendering. The pipeline is capable of synthesizing scene layouts with high diversity, and it is configurable inasmuch as it enables the precise customization and control of important attributes of the generated scenes. It renders photorealistic RGB images of the generated scenes while automatically synthesizing detailed, per-pixel ground truth data, including visible surface depth and normal, object identity, and material information (detailed to object parts), as well as environments (e.g., illuminations and camera viewpoints). The authors demonstrate the value of the synthesized dataset, by improving performance in certain machine-learning-based scene understanding tasks—depth and surface normal prediction, semantic segmentation, reconstruction, etc.---and by providing benchmarks for and diagnostics of trained models by modifying object attributes and scene properties in a controllable manner.",
          "title": "Configurable 3D Scene Synthesis and 2D Image Rendering with Per-pixel Ground Truth Using Stochastic Grammars"
        },
        {
          "children": [],
          "description": "2025. []. []. This paper introduces the Scene Language, a visual scene representation that concisely and precisely describes the structure, semantics, and identity of visual scenes. It represents a scene with three key components: a program that specifies the hierarchical and relational structure of entities in the scene, words in natural language that summarize the semantic class of each entity, and embeddings that capture the visual identity of each entity. This representation can be inferred from pre-trained language models via a training-free inference technique, given text or image inputs.",
          "title": "The Scene Language: Representing Scenes with Programs, Words, and Embeddings"
        },
        {
          "children": [],
          "description": "2021. []. Pathological changes in alternative splicing patterns are considered a hallmark of cancer, yet the underlying regulatory programs that control this process remain largely unknown. A major obstacle to better understanding these programs is that the bioinformatic strategies commonly used for the discovery of cis-regulatory elements fail to capture the contribution of RNA secondary structure to regulatory information. To address this, this work had previously developed the computational framework TEISER (Tool for Eliciting Informative Structural Elements in RNA), which uses both RNA structural and sequence information to identify cis-regulatory elements that are informative of transcriptomic changes. Here, the authors introduce pyTEISER (pythonic TEISER), which incorporates experimentally derived and additional computationally predicted RNA structural information to investigate the RNA sequence and structural code that governs a broader range of RNA-related processes, including splicing and RNA processing, in addition to steady-state gene expression.",
          "title": "A prometastatic splicing program regulated by SNRPA1 interactions with structured RNA elements"
        },
        {
          "children": [],
          "description": "2025. []. []. People are remarkably capable of generating their own goals, beginning with child’s play and continuing into adulthood. Despite considerable empirical and computational work on goals and goal-oriented behaviour, models are still far from capturing the richness of everyday human goals. This work bridges this gap by collecting a dataset of human-generated playful goals (in the form of scorable, single-player games), modelling them as reward-producing programs and generating novel human-like goals through program synthesis. Reward-producing programs capture the rich semantics of goals through symbolic operations that compose, add temporal constraints and allow program execution on behavioural traces to evaluate progress. To build a generative model of goals, the authors learn a fitness function over the infinite set of possible goal programs and sample novel goals with a quality-diversity algorithm. Human evaluators found that model-generated goals, when sampled from partitions of program space occupied by human examples, were indistinguishable from human-created games. The authors also discovered that the model’s internal fitness scores predict games that are evaluated as more fun to play and more human-like.",
          "title": "Goals as reward-producing programs",
          "repo_info": {
            "archived": false,
            "language": "Jupyter Notebook",
            "last_commit": "2024-12-05T05:09:48Z",
            "owner": "guydav",
            "repo": "goals-as-reward-producing-programs",
            "stars": 13
          }
        },
        {
          "children": [],
          "description": "2020. []. Detection, parsing, and future predictions on sequence data (e.g., videos) require the algorithms to capture non-Markovian and compositional properties of high-level semantics. Context-free grammars are natural choices to capture such properties, but traditional grammar parsers (e.g., Earley parser) only take symbolic sentences as inputs. This paper generalizes the Earley parser to parse sequence data which is neither segmented nor labeled. Given the output of an arbitrary probabilistic classifier, this generalized Earley parser finds the optimal segmentation and labels in the language defined by the input grammar. Based on the parsing results, it makes top-down future predictions. The proposed method is generic, principled, and widely applicable. Experiment results clearly show the benefit of the method for both human activity parsing and prediction on three video datasets.",
          "title": "A Generalized Earley Parser for Human Activity Parsing and Prediction"
        },
        {
          "children": [],
          "description": "2025. []. This position paper argues for the use of structured generative models (SGMs) for the understanding of static scenes. This requires the reconstruction of a 3D scene from an input image (or a set of multi-view images), whereby the contents of the image(s) are causally explained in terms of models of instantiated objects, each with their own type, shape, appearance and pose, along with global variables like scene lighting and camera parameters. This approach also requires scene models which account for the co-occurrences and inter-relationships of objects in a scene. The SGM approach has the merits that it is compositional and generative, which lead to interpretability and editability. To pursue the SGM agenda, people need models for objects and scenes, and approaches to carry out inference. The authors first review models for objects, which include “things” (object categories that have a well defined shape), and “stuff” (categories which have amorphous spatial extent). The authors then move on to review scene models which describe the inter-relationships of objects. Perhaps the most challenging problem for SGMs is inference of the objects, lighting and camera parameters, and scene inter-relationships from input consisting of a single or multiple images. The authors conclude with a discussion of issues that need addressing to advance the SGM agenda.",
          "title": "Structured Generative Models for Scene Understanding"
        },
        {
          "children": [],
          "description": "2023. []. Messenger RNA (mRNA) vaccines are being used to combat the spread of COVID-19, but they still exhibit critical limitations caused by mRNA instability and degradation, which are major obstacles for the storage, distribution and efficacy of the vaccine products. Increasing secondary structure lengthens mRNA half-life, which, together with optimal codons, improves protein expression. Therefore, a principled mRNA design algorithm must optimize both structural stability and codon usage. However, owing to synonymous codons, the mRNA design space is prohibitively large---for example, there are around 2.4 × 10632 candidate mRNA sequences for the SARS-CoV-2 spike protein. This poses insurmountable computational challenges. This work provides a simple and unexpected solution using the classical concept of lattice parsing in computational linguistics, where finding the optimal mRNA sequence is analogous to identifying the most likely sentence among similar-sounding alternatives6. The algorithm LinearDesign finds an optimal mRNA design for the spike protein in just 11 minutes, and can concurrently optimize stability and codon usage. LinearDesign substantially improves mRNA half-life and protein expression, and profoundly increases antibody titre by up to 128 times in mice compared to the codon-optimization benchmark on mRNA vaccines for COVID-19 and varicella-zoster virus. This result reveals the great potential of principled mRNA design and enables the exploration of previously unreachable but highly stable and efficient designs. This work is a timely tool for vaccines and other mRNA-based medicines encoding therapeutic proteins such as monoclonal antibodies and anti-cancer drugs7,8.",
          "title": "Algorithm for optimized mRNA design improves stability and immunogenicity"
        },
        {
          "children": [],
          "description": "2020. []. This work introduces a system called Penrose for creating mathematical diagrams. Its basic functionality is to translate abstract statements written in familiar math-like notation into one or more possible visual representations. Rather than rely on a fixed library of visualization tools, the visual representation is user-defined in a constraint-based specification language; diagrams are then generated automatically via constrained numerical optimization. The system is user-extensible to many domains of mathematics, and is fast enough for iterative design exploration. In contrast to tools that specify diagrams via direct manipulation or low-level graphics programming, Penrose enables rapid creation and exploration of diagrams that faithfully preserve the underlying mathematical meaning. The authors demonstrate the effectiveness and generality of the system by showing how it can be used to illustrate a diverse set of concepts from mathematics and computer graphics.",
          "title": "Penrose: from mathematical notation to beautiful diagrams"
        },
        {
          "children": [],
          "description": "2019. []. Nowadays legal ontologies have been used in the legal domain, however, being poorly explored in legislative and production processes. This paper analyses the adoption of legal ontologies as a tool to support these processes, in particular, related to activities span from the submission of bills and their subsequent authoring and ratification. This paper introduces the state of the art of legal (or normative) ontologies; and also discusses some application examples. The analysis of this state of the art allows us to identify some problems, namely regarding the activities involving the authoring and validation of laws that tend to be very human-intensive and error-prone. As a consequence of this analysis, the authors introduce the LegalLanguage, a language particularly suitable for the authoring and specification of law(s) in a more rigorous and systematic way, that would allow to keep track different types of intra and inter-laws relationships (e.g., structural, order or temporal relationships between articles or even between laws).",
          "title": "LegalLanguage: A Domain-Specific Language for Legal Contexts"
        },
        {
          "children": [],
          "description": "2023. []. Garment modeling is an essential task of the global apparel industry and a core part of digital human modeling. Realistic representation of garments with valid sewing patterns is key to their accurate digital simulation and eventual fabrication. However, little-to-no computational tools provide support for bridging the gap between high-level construction goals and low-level editing of pattern geometry, e.g., combining or switching garment elements, semantic editing, or design exploration that maintains the validity of a sewing pattern. This work suggests the first DSL for garment modeling - GarmentCode - that applies principles of object-oriented programming to garment construction and allows designing sewing patterns in a hierarchical, component-oriented manner. The programming-based paradigm naturally provides unique advantages of component abstraction, algorithmic manipulation, and free-form design parametrization. The authors additionally support the construction process by automating typical low-level tasks like placing a dart at a desired location. In the prototype garment configurator, users can manipulate meaningful design parameters and body measurements, while the construction of pattern geometry is handled by garment programs implemented with GarmentCode.",
          "title": "GarmentCode: Programming Parametric Sewing Patterns"
        },
        {
          "children": [],
          "description": "2024. []. Visualizations play a critical role in validating and improving statistical models. However, the design space of model check visualizations is not well understood, making it difficult for authors to explore and specify effective graphical model checks. VMC defines a model check visualization using four components: (1) samples of distributions of checkable quantities generated from the model, including predictive distributions for new data and distributions of model parameters; (2) transformations on observed data to facilitate comparison; (3) visual representations of distributions; and (4) layouts to facilitate comparing model samples and observed data. This work contributes an implementation of VMC as an R package. The authors validate VMC by reproducing a set of canonical model check examples, and show how using VMC to generate model checks reduces the edit distance between visualizations relative to existing visualization toolkits. The findings of an interview study with three expert modelers who used VMC highlight challenges and opportunities for encouraging exploration of correct, effective model check visualizations.",
          "title": "VMC: A Grammar for Visualizing Statistical Model Checks"
        },
        {
          "children": [],
          "description": "2020. []. This work presents RoboGrammar, a fully automated approach for generating optimized robot structures to traverse given terrains. This framework represents each robot design as a graph, and uses a graph grammar to express possible arrangements of physical robot assemblies. Each robot design can then be expressed as a sequence of grammar rules. Using only a small set of rules the grammar can describe hundreds of thousands of possible robot designs. The construction of the grammar limits the design space to designs that can be fabricated. For a given input terrain, the design space is searched to find the top performing robots and their corresponding controllers. The authors introduce Graph Heuristic Search - a novel method for efficient search of combinatorial design spaces. In Graph Heuristic Search, the authors explore the design space while simultaneously learning a function that maps incomplete designs (e.g., nodes in the combinatorial search tree) to the best performance values that can be achieved by expanding these incomplete designs. Graph Heuristic Search prioritizes exploration of the most promising branches of the design space. To test the method the authors optimize robots for a number of challenging and varied terrains. The authors demonstrate that RoboGrammar can successfully generate nontrivial robots that are optimized for a single terrain or a combination of terrains.",
          "title": "RoboGrammar: graph grammar for terrain-optimized robot design"
        }
      ],
      "title": "Declarative DSL Applications"
    },
    {
      "description": "",
      "items": [
        {
          "children": [],
          "description": "2018. []. The method learns a model that uses program synthesis techniques to recover a graphics program from drawing primitives. These programs have constructs like variable bindings, iterative loops, or simple kinds of conditionals. With a graphics program in hand, we can correct errors made by the deep network and extrapolate drawings.",
          "title": "Learning to Infer Graphics Programs from Hand-Drawn Images"
        },
        {
          "children": [],
          "description": "2023. []. This paper proposes library learning modulo theory (LLMT), a new library learning algorithm that additionally takes as input an equational theory for a given problem domain. LLMT uses e-graphs and equality saturation to compactly represent the space of programs equivalent modulo the theory, and uses a novel e-graph anti-unification technique to find common patterns in the corpus more directly and efficiently.",
          "title": "babble: Learning Better Abstractions with E-Graphs and Anti-unification"
        },
        {
          "children": [],
          "description": "2023. []. This paper introduces corpus-guided top-down synthesis as a mechanism for synthesizing library functions that capture common functionality from a corpus of programs in a domain specific language (DSL). The algorithm builds abstractions directly from initial DSL primitives, using syntactic pattern matching of intermediate abstractions to intelligently prune the search space and guide the algorithm towards abstractions that maximally capture shared structures in the corpus.",
          "title": "Top-Down Synthesis for Library Learning"
        },
        {
          "children": [],
          "description": "2023. []. []. This paper presents DreamCoder, a system that learns to solve problems by writing programs. It builds expertise by creating domain-specific programming languages for expressing domain concepts, together with neural networks to guide the search for programs within these languages. A ‘wake–sleep’ learning algorithm alternately extends the language with new symbolic abstractions and trains the neural network on imagined and replayed problems. DreamCoder solves both classic inductive programming tasks and creative tasks such as drawing pictures and building scenes.",
          "title": "DreamCoder: growing generalizable, interpretable knowledge with wake–sleep Bayesian program learning"
        },
        {
          "children": [],
          "description": "2022. []. Automated, data-driven construction and evaluation of scientific models and theories is a long-standing challenge in artificial intelligence. This work presents a framework for algorithmically synthesizing models of a basic part of human language: morpho-phonology, the system that builds word forms from sounds. The authors integrate Bayesian inference with program synthesis and representations inspired by linguistic theory and cognitive models of learning and discovery. Across 70 datasets from 58 diverse languages, the system synthesizes human-interpretable models for core aspects of each language’s morpho-phonology, sometimes approaching models posited by human linguists. Joint inference across all 70 data sets automatically synthesizes a meta-model encoding interpretable cross-language typological tendencies. Finally, the same algorithm captures few-shot learning dynamics, acquiring new morphophonological rules from just one or a few examples. These results suggest routes to more powerful machine-enabled discovery of interpretable models in linguistics and other scientific domains.",
          "title": "Synthesizing theories of human language with Bayesian program induction"
        },
        {
          "children": [],
          "description": "2023. []. Grammar prompting is a simple approach to enable LLMs to use external knowledge and domain-specific constraints expressed through a grammar in Backus--Naur Form (BNF) during in-context learning. Grammar prompting augments each demonstration example with a specialized grammar that is minimally sufficient for generating the particular output example, where the specialized grammar is a subset of the full DSL grammar. For inference, the LLM first predicts a BNF grammar given a test input, and then generates the output according to the rules of the grammar. Experiments demonstrate that grammar prompting can enable LLMs to perform competitively on a diverse set of DSL generation tasks, including semantic parsing (SMCalFlow, Overnight, GeoQuery), PDDL planning, and SMILES-based molecule generation.",
          "title": "Grammar Prompting for Domain-Specific Language Generation with Large Language Models"
        },
        {
          "children": [],
          "description": "2023. []. []. []. This paper proposes CLAIRIFY, an approach that combines automatic iterative prompting with program verification to ensure programs written in data-scarce domain-specific language are syntactically valid and incorporate environment constraints.",
          "title": "Errors are Useful Prompts: Instruction Guided Task Programming with Verifier-Assisted Iterative Prompting",
          "repo_info": {
            "archived": false,
            "language": "JavaScript",
            "last_commit": "2024-12-06T12:21:08Z",
            "owner": "ac-rad",
            "repo": "xdl-generation",
            "stars": 47
          }
        },
        {
          "children": [],
          "description": "2024. []. This paper explores a new multi-modal image search approach that allows users to conveniently specify and perform semantic image search tasks. With the tool, PhotoScout, the user interactively provides natural language descriptions, positive and negative examples, and object tags to specify their search tasks. Under the hood, PhotoScout is powered by a program synthesis engine that generates visual queries in a domain-specific language and executes the synthesized program to retrieve the desired images.",
          "title": "PhotoScout: Synthesis-Powered Multi-Modal Image Search"
        },
        {
          "children": [],
          "description": "2024. []. []. Recent development in Artificial Intelligence (AI) models has propelled their application in scientific discovery, but the validation and exploration of these discoveries require subsequent empirical experimentation. The concept of self-driving laboratories promises to automate and thus boost the experimental process following AI-driven discoveries. However, the transition of experimental protocols, originally crafted for human comprehension, into formats interpretable by machines presents significant challenges, which, within the context of specific expert domain, encompass the necessity for structured as opposed to natural language, the imperative for explicit rather than tacit knowledge, and the preservation of causality and consistency throughout protocol steps. Presently, the task of protocol translation predominantly requires the manual and labor-intensive involvement of domain experts and information technology specialists, rendering the process time-intensive. To address these issues, this work proposes a framework that automates the protocol translation process through a three-stage workflow, which incrementally constructs Protocol Dependence Graphs (PDGs) that approach structured on the syntax level, completed on the semantics level, and linked on the execution level. Quantitative and qualitative evaluations have demonstrated its performance at par with that of human experts, underscoring its potential to significantly expedite and democratize the process of scientific discovery by elevating the automation capabilities within self-driving laboratories.",
          "title": "Expert-level protocol translation for self-driving labs"
        },
        {
          "children": [],
          "description": "2024. []. Large language models (LLMs) have demonstrated tremendous capabilities in solving complex tasks, from quantitative reasoning to understanding natural language. However, LLMs sometimes suffer from confabulations (or hallucinations), which can result in them making plausible but incorrect statements1,2. This hinders the use of current large models in scientific discovery. This work introduces FunSearch (short for searching in the function space), an evolutionary procedure based on pairing a pretrained LLM with a systematic evaluator. The authors demonstrate the effectiveness of this approach to surpass the best-known results in important problems, pushing the boundary of existing LLM-based approaches3. Applying FunSearch to a central problem in extremal combinatorics—the cap set problem—we discover new constructions of large cap sets going beyond the best-known ones, both in finite dimensional and asymptotic cases. This shows that it is possible to make discoveries for established open problems using LLMs. The authors showcase the generality of FunSearch by applying it to an algorithmic problem, online bin packing, finding new heuristics that improve on widely used baselines. In contrast to most computer search approaches, FunSearch searches for programs that describe how to solve a problem, rather than what the solution is. Beyond being an effective and scalable strategy, discovered programs tend to be more interpretable than raw solutions, enabling feedback loops between domain experts and FunSearch, and the deployment of such programs in real-world applications.",
          "title": "Mathematical discoveries from program search with large language models"
        },
        {
          "children": [],
          "description": "2024. []. This paper adopted an iterative design process to gain insights into programmers’ strategies when using LLMs for programming. The authors proposed CoLadder, a novel system that supports programmers by facilitating hierarchical task decomposition, direct code segment manipulation, and result evaluation during prompt authoring. A user study with 12 experienced programmers showed that CoLadder is effective in helping programmers externalize their problem-solving intentions flexibly, improving their ability to evaluate and modify code across various abstraction levels, from their task’s goal to final code implementation.",
          "title": "CoLadder: Manipulating Code Generation via Multi-Level Blocks"
        },
        {
          "children": [],
          "description": "2018. []. While computer-aided design is a major part of many modern manufacturing pipelines, the design files typically generated describe raw geometry. Lost in this representation is the procedure by which these designs were generated. This paper presents a method for reverse-engineering the process by which 3D models may have been generated, in the language of constructive solid geometry (CSG). Observing that CSG is a formal grammar, the authors formulate this inverse CSG problem as a program synthesis problem. The solution is an algorithm that couples geometric processing with state-of-the-art program synthesis techniques. In this scheme, geometric processing is used to convert the mixed discrete and continuous domain of CSG trees to a pure discrete domain where modern program synthesizers excel. The authors demonstrate the efficiency and scalability of the algorithm on several different examples, including those with over 100 primitive parts. The authors show that the algorithm is able to find simple programs which are close to the ground truth, and demonstrate the method's applicability in mesh re-editing. Finally, the authors compare the method to prior state-of-the-art. The authors demonstrate that the algorithm dominates previous methods in terms of resulting CSG compactness and runtime, and can handle far more complex input meshes than any previous method.",
          "title": "InverseCSG: automatic conversion of 3D models to CSG trees"
        },
        {
          "children": [],
          "description": "2018. []. []. []. This paper shows that deep learning methods can be leveraged to train a model end-to-end to automatically reverse engineer user interfaces and generate code from a single input image with over 77% of accuracy for three different platforms (i.e. iOS, Android and web-based technologies).",
          "title": "pix2code: Generating Code from a Graphical User Interface Screenshot",
          "repo_info": {
            "archived": false,
            "language": "Python",
            "last_commit": "2024-05-29T04:48:27Z",
            "owner": "tonybeltramelli",
            "repo": "pix2code",
            "stars": 12055
          }
        },
        {
          "children": [],
          "description": "2022. []. CAD modeling, despite being the industry-standard, remains restricted to usage by skilled practitioners due to two key barriers. First, the user must be able to mentally parse a final shape into a valid sequence of supported CAD commands; and second, the user must be sufficiently conversant with CAD software packages to be able to execute the corresponding CAD commands. As a step towards addressing both these challenges, this work presents Free2CAD wherein the user can simply sketch the final shape and the system parses the input strokes into a sequence of commands expressed in a simplified CAD language. When executed, these commands reproduce the sketched object. Technically, the authors cast sketch-based CAD modeling as a sequence-to-sequence translation problem, for which the authors leverage the powerful Transformers neural network architecture. Given the sequence of pen strokes as input, the authors introduce the new task of grouping strokes that correspond to individual CAD operations. The authors combine stroke grouping with geometric fitting of the operation parameters, such that intermediate groups are geometrically corrected before being reused, as context, for subsequent steps in the sequence inference. Although trained on synthetically-generated data, the authors demonstrate that Free2CAD generalizes to sketches created from real-world CAD models as well as to sketches drawn by novice users.",
          "title": "Free2CAD: parsing freehand drawings into CAD commands"
        },
        {
          "children": [],
          "description": "2020. []. Manually authoring 3D shapes is difficult and time consuming; generative models of 3D shapes offer compelling alternatives. Procedural representations are one such possibility: they offer high-quality and editable results but are difficult to author and often produce outputs with limited diversity. On the other extreme are deep generative models: given enough data, they can learn to generate any class of shape but their outputs have artifacts and the representation is not editable. This work takes a step towards achieving the best of both worlds for novel 3D shape synthesis. The authors propose ShapeAssembly, a domain-specific \"assembly-language\" for 3D shape structures. ShapeAssembly programs construct shape structures by declaring cuboid part proxies and attaching them to one another, in a hierarchical and symmetrical fashion. ShapeAssembly functions are parameterized with continuous free variables, so that one program structure is able to capture a family of related shapes. The authors show how to extract ShapeAssembly programs from existing shape structures in the PartNet dataset. Then, the authors train a deep generative model, a hierarchical sequence VAE, that learns to write novel ShapeAssembly programs. The approach leverages the strengths of each representation: the program captures the subset of shape variability that is interpretable and editable, and the deep generative model captures variability and correlations across shape collections that is hard to express procedurally.",
          "title": "ShapeAssembly: learning to generate programs for 3D shape structure synthesis"
        },
        {
          "children": [],
          "description": "2021. []. A popular way to create detailed yet easily controllable 3D shapes is via procedural modeling, i.e. generating geometry using programs. Such programs consist of a series of instructions along with their associated parameter values. To fully realize the benefits of this representation, a shape program should be compact and only expose degrees of freedom that allow for meaningful manipulation of output geometry. One way to achieve this goal is to design higher-level macro operators that, when executed, expand into a series of commands from the base shape modeling language. However, manually authoring such macros, much like shape programs themselves, is difficult and largely restricted to domain experts. This paper presents ShapeMOD, an algorithm for automatically discovering macros that are useful across large datasets of 3D shape programs. ShapeMOD operates on shape programs expressed in an imperative, statement-based language. It is designed to discover macros that make programs more compact by minimizing the number of function calls and free parameters required to represent an input shape collection. The authors run ShapeMOD on multiple collections of programs expressed in a domain-specific language for 3D shape structures. The authors show that it automatically discovers a concise set of macros that abstract out common structural and parametric patterns that generalize over large shape collections. The authors also demonstrate that the macros found by ShapeMOD improve performance on downstream tasks including shape generative modeling and inferring programs from point clouds. Finally, the authors conduct a user study that indicates that ShapeMOD's discovered macros make interactive shape editing more efficient.",
          "title": "ShapeMOD: macro operation discovery for 3D shape programs"
        },
        {
          "children": [],
          "description": "2023. []. This work introduces ShapeCoder, the first system capable of taking a dataset of shapes, represented with unstructured primitives, and jointly discovering (i) useful abstraction functions and (ii) programs that use these abstractions to explain the input shapes. The discovered abstractions capture common patterns (both structural and parametric) across a dataset, so that programs rewritten with these abstractions are more compact, and suppress spurious degrees of freedom. ShapeCoder improves upon previous abstraction discovery methods, finding better abstractions, for more complex inputs, under less stringent input assumptions. This is principally made possible by two methodological advancements: (a) a shape-to-program recognition network that learns to solve sub-problems and (b) the use of e-graphs, augmented with a conditional rewrite scheme, to determine when abstractions with complex parametric expressions can be applied, in a tractable manner. The authors evaluate ShapeCoder on multiple datasets of 3D shapes, where primitive decompositions are either parsed from manual annotations or produced by an unsupervised cuboid abstraction method. In all domains, ShapeCoder discovers a library of abstractions that captures high-level relationships, removes extraneous degrees of freedom, and achieves better dataset compression compared with alternative approaches. Finally, the authors investigate how programs rewritten to use discovered abstractions prove useful for downstream tasks.",
          "title": "ShapeCoder: Discovering Abstractions for Visual Programs from Unstructured Primitives"
        },
        {
          "children": [],
          "description": "2020. []. Movement primitives are a well studied and widely applied concept in modern robotics. However, composing primitives out of an existing library has shown to be a challenging problem. This work proposes the use of probabilistic context-free grammars to sequence a series of primitives to generate complex robot policies from a given library of primitives. The rule-based nature of formal grammars allows an intuitive encoding of hierarchically structured tasks. This hierarchical concept strongly connects with the way robot policies can be learned, organized, and re-used. However, the induction of context-free grammars has proven to be a complicated and yet unsolved challenge. The authors exploit the physical nature of robot movement primitives to restrict and efficiently search the grammar space. The grammar is learned by applying a Markov chain Monte Carlo optimization over the posteriors of the grammars given the observations. The proposal distribution is defined as a mixture over the probabilities of the operators connecting the search space. Moreover, the authors present an approach for the categorization of probabilistic movement primitives and discuss how the connectibility of two primitives can be determined. These characteristics in combination with restrictions to the operators guarantee continuous sequences while reducing the grammar space. In addition, a set of attributes and conditions is introduced that augments probabilistic context-free grammars in order to solve primitive sequencing tasks with the capability to adapt single primitives within the sequence. The method was validated on tasks that require the generation of complex sequences consisting of simple movement primitives using a seven-degree-of-freedom lightweight robotic arm.",
          "title": "Learning attribute grammars for movement primitive sequencing"
        },
        {
          "children": [],
          "description": "2024. []. This paper presents LogiCode, a novel framework that leverages Large Language Models (LLMs) for identifying logical anomalies in industrial settings, moving beyond the traditional focus on structural inconsistencies. By harnessing LLMs for logical reasoning, LogiCode autonomously generates Python codes to pinpoint anomalies such as incorrect component quantities or missing elements, marking a significant leap forward in anomaly detection technologies. A custom dataset “LOCO-Annotations” and a benchmark “LogiBench” are introduced to evaluate the LogiCode’s performance across various metrics including binary classification accuracy, code generation success rate, and precision in reasoning. Findings demonstrate LogiCode’s enhanced interpretability, significantly improving the accuracy of logical anomaly detection and offering detailed explanations for identified anomalies. This represents a notable shift towards more intelligent, LLM-driven approaches in industrial anomaly detection, promising substantial impacts on industry-specific applications.",
          "title": "LogiCode: An LLM-Driven Framework for Logical Anomaly Detection"
        },
        {
          "children": [],
          "description": "2020. []. This article targets the Incremental View Maintenance (IVM) of sophisticated analytics (such as statistical models, machine learning programs, and graph algorithms) expressed as linear algebra programs. This work presents LAGO, a unified framework for linear algebra that automatically synthesizes efficient incremental trigger programs, thereby freeing the user from error-prone manual derivations, performance tuning, and low-level implementation details. The key technique underlying the framework is abstract interpretation, which is used to infer various properties of analytical programs. These properties give the reasoning power required for the automatic synthesis of efficient incremental triggers. The authors evaluate the effectiveness of the framework on a wide range of applications from regression models to graph computations.",
          "title": "Synthesis of Incremental Linear Algebra Programs"
        },
        {
          "children": [],
          "description": "2023. []. Program synthesis aims to automatically generate an executable program that conforms to the given specification. Recent advancements have demonstrated that deep neural methodologies and large-scale pretrained language models are highly proficient in capturing program semantics. For robot programming, prior works have facilitated program synthesis by incorporating global environments. However, the assumption of acquiring a comprehensive understanding of the entire environment is often excessively challenging to achieve. This work presents a framework that learns to synthesize a program by rectifying potentially erroneous code segments, with the aid of partially observed environments. To tackle the issue of inadequate attention to partial observations, the authors propose to first learn an environment embedding space that can implicitly evaluate the impacts of each program token based on the precondition. Furthermore, by employing a graph structure, the model can aggregate both environmental and syntactic information flow and furnish smooth program rectification guidance. Extensive experimental evaluations and ablation studies on the partially observed VizDoom domain authenticate that the method offers superior generalization capability across various tasks and greater robustness when encountering noises.",
          "title": "Enhancing Robot Program Synthesis Through Environmental Context"
        },
        {
          "children": [],
          "description": "2025. []. Large language models (LLMs) such as ChatGPT have shown remarkable capabilities in code generation. Despite significant achievements, they rely on enormous training data to acquire a broad spectrum of open-domain knowledge. Besides, their evaluation revolves around open-domain benchmarks like HumanEval, which primarily consist of programming contests. Therefore, it is hard to fully characterize the intricacies and challenges associated with particular domains (e.g., Web, game, and math). This work conducts an in-depth study of the LLMs in domain-specific code generation. The results demonstrate that LLMs exhibit sub-optimal performance in generating domain-specific code, due to their limited proficiency in utilizing domain-specific libraries. The authors further observe that incorporating API knowledge as prompts can empower LLMs to generate more professional code. Based on these findings, the authors further investigate how to effectively incorporate API knowledge into the code generation process. The authors experiment with three strategies for incorporating domain knowledge, namely, external knowledge inquirer, chain-of-thought prompting, and chain-of-thought fine-tuning. The authors refer to these strategies as a new code generation approach called DomCoder. Experimental results show that all strategies of DomCoder improve the effectiveness of domain-specific code generation under certain settings.",
          "title": "On the Effectiveness of Large Language Models in Domain-Specific Code Generation"
        }
      ],
      "title": "DSL Program Synthesis"
    },
    {
      "description": "",
      "items": [],
      "title": "Problem Solving"
    },
    {
      "description": "",
      "items": [
        {
          "children": [],
          "description": "2018. []. Richard Sutton's comprehensive book on reinforcement learning.",
          "title": "Reinforcement learning: An introduction"
        },
        {
          "children": [],
          "description": "1996. []. Leslie Kaelbling's review on reinforcement learning.",
          "title": "Reinforcement learning: A survey"
        },
        {
          "children": [],
          "description": "2020. []. Yaodong Yang's review on multi-agent reinforcement learning from the perspective of game theory.",
          "title": "An overview of multi-agent reinforcement learning from game theoretical perspective"
        },
        {
          "children": [],
          "description": "2015. []. The original paper on solving Atari games via Deep Q-Network.",
          "title": "Human-level control through deep reinforcement learning"
        },
        {
          "children": [],
          "description": "1999. []. The original paper on operation reinforcement learning.",
          "title": "Between MDPs and semi-MDPs: A framework for temporal abstraction in reinforcement learning"
        },
        {
          "children": [],
          "description": "2017. [].",
          "title": "On Monte Carlo Tree Search and Reinforcement Learning"
        },
        {
          "children": [],
          "description": "2018. []. []. Sergey Levine's tutorial on treating reinforcement learning probabilisticly.",
          "title": "Reinforcement Learning and Control as Probabilistic Inference: Tutorial and Review"
        },
        {
          "children": [],
          "description": "2019. [].",
          "title": "A Generalized Algorithm for Multi-Objective Reinforcement Learning and Policy Adaptation"
        },
        {
          "children": [],
          "description": "2021. [].",
          "title": "Solving Compositional Reinforcement Learning Problems via Task Reduction"
        },
        {
          "children": [],
          "description": "2018. [].",
          "title": "Neural Task Programming: Learning to Generalize Across Hierarchical Tasks"
        },
        {
          "children": [],
          "description": "2017. [].",
          "title": "Learning to act: qualitative learning of deterministic action models"
        },
        {
          "children": [],
          "description": "2021. [].",
          "title": "Learning to Act and Observe in Partially Observable Domains"
        },
        {
          "children": [],
          "description": "2021. []. A formal treatment on the generalization problem in reinforcement learning.",
          "title": "Why Generalization in RL is Difficult: Epistemic POMDPs and Implicit Partial Observability"
        },
        {
          "children": [],
          "description": "2017. [].",
          "title": "Learning to Perform Physics Experiments via Deep Reinforcement Learning"
        },
        {
          "children": [],
          "description": "2021. [].",
          "title": "Data-Efficient Learning for Complex and Real-Time Physical Problem Solving Using Augmented Simulation"
        },
        {
          "children": [],
          "description": "2017. [].",
          "title": "A Survey of Preference-Based Reinforcement Learning Methods"
        },
        {
          "children": [],
          "description": "2021. []. A formal treatment of tasks and rewards in reinforcement learning modeling.",
          "title": "On the Expressivity of Markov Reward"
        },
        {
          "children": [],
          "description": "2015. []. The original paper introducing TRPO, a method for optimizing control policies, with guaranteed monotonic improvement.",
          "title": "Trust Region Policy Optimization"
        },
        {
          "children": [],
          "description": "2017. []. The original paper on constrained reinforcement learning (safe reinforcement learning).",
          "title": "Constrained Policy Optimization"
        },
        {
          "children": [],
          "description": "2019. []. [].",
          "title": "When to Trust Your Model: Model-Based Policy Optimization"
        },
        {
          "children": [],
          "description": "2021. []. [].",
          "title": "SUNRISE: A Simple Unified Framework for Ensemble Learning in Deep Reinforcement Learning",
          "repo_info": {
            "archived": false,
            "language": "Python",
            "last_commit": "2021-03-21T06:58:47Z",
            "owner": "pokaxpoka",
            "repo": "sunrise",
            "stars": 130
          }
        },
        {
          "children": [],
          "description": "2022. []. Richard Sutton's perspective on the future directions of reinforcement learning research.",
          "title": "The Quest for a Common Model of the Intelligent Decision Maker"
        },
        {
          "children": [],
          "description": "2020. [].",
          "title": "Automatic curriculum learning for deep RL: a short survey"
        },
        {
          "children": [],
          "description": "2021. []. [].",
          "title": "TeachMyAgent: a Benchmark for Automatic Curriculum Learning in Deep RL",
          "repo_info": {
            "archived": false,
            "language": "Jupyter Notebook",
            "last_commit": "2023-11-21T12:26:05Z",
            "owner": "flowersteam",
            "repo": "TeachMyAgent",
            "stars": 76
          }
        }
      ],
      "title": "Reinforcement Learning"
    },
    {
      "description": "",
      "items": [],
      "title": "System 1 & System 2"
    },
    {
      "description": "",
      "items": [
        {
          "children": [],
          "description": "2025. []. Advances in artificial intelligence (AI), particularly large language models (LLMs), have achieved remarkable success. This progress stems from ‘scaling laws’---performance improves with greater computation, data and model size. However, this paradigm has a crucial vulnerability: scaling laws are effective only when data are abundant. A foundational process for this is the human ability of ‘quotienting’: creating a compact symbolic space from a vast problem space, in a process akin to forming a mathematical quotient space via equivalence classes. The new strategy uses symbols as vessels for compressed human wisdom, creating maps that guide the powerful statistical intuition of LLMs, which is especially critical for tackling complex problems where usable data are, by nature, sparse. The next frontier for AI will not be conquered by scaling alone. The art of symbolization itself—the crafting of powerful abstractions—is therefore the central task ahead. If scaling laws have given models their powerful intuition, it is the art of the symbol that will provide the compass for genuine discovery.",
          "title": "How large language models need symbolism"
        },
        {
          "children": [],
          "description": "2000. []. The original paper on symbolic regression.",
          "title": "Regression Analysis for Interval-Valued Data"
        },
        {
          "children": [],
          "description": "2006. [].",
          "title": "Symbolic data analysis: what is it?"
        },
        {
          "children": [],
          "description": "2018. []. The original paper on neuro-symbolic probabilistic programming.",
          "title": "DeepProbLog: Neural Probabilistic Logic Programming"
        },
        {
          "children": [],
          "description": "2018. []. The original paper for differential Inductive Logic Programming.",
          "title": "Learning Explanatory Rules from Noisy Data"
        },
        {
          "children": [],
          "description": "2017. [].",
          "title": "Combining Logical Abduction and Statistical Induction: Discovering Written Primitives with Human Knowledge"
        },
        {
          "children": [],
          "description": "2019. [].",
          "title": "Neural Logic Reinforcement Learning"
        },
        {
          "children": [],
          "description": "2019. []. []. []. The original paper on Abductive Learning, a derivative-free approach for neuro-symbolic learning.",
          "title": "Bridging Machine Learning and Logical Reasoning by Abductive Learning.",
          "repo_info": {
            "archived": false,
            "language": "Python",
            "last_commit": "2024-01-31T05:41:45Z",
            "owner": "AbductiveLearning",
            "repo": "ABL-HED",
            "stars": 100
          }
        },
        {
          "children": [],
          "description": "2019. [].",
          "title": "Abductive learning: towards bridging machine learning and logical reasoning"
        },
        {
          "children": [],
          "description": "2021. [].",
          "title": "Abductive Knowledge Induction From Raw Data"
        },
        {
          "children": [],
          "description": "2021. []. An approach for accelerating the convergence of Abductive Learning.",
          "title": "Fast Abductive Learning by Similarity-based Consistency Optimization"
        },
        {
          "children": [],
          "description": "2019. [].",
          "title": "Learning by Abstraction: The Neural State Machine"
        },
        {
          "children": [],
          "description": "2021. [].",
          "title": "Making sense of sensory input"
        },
        {
          "children": [],
          "description": "2021. [].",
          "title": "Abstract Spatial-Temporal Reasoning via Probabilistic Abduction and Execution"
        },
        {
          "children": [],
          "description": "2020. []. [].",
          "title": "Learn to explain efﬁciently via neural logic inductive learning",
          "repo_info": {
            "archived": false,
            "language": "Python",
            "last_commit": "2022-08-06T22:36:18Z",
            "owner": "gblackout",
            "repo": "NLIL",
            "stars": 44
          }
        },
        {
          "children": [],
          "description": "2020. [].",
          "title": "Closed Loop Neural-Symbolic Learning via Integrating Neural Perception, Grammar Parsing, and Symbolic Reasoning"
        },
        {
          "children": [],
          "description": "2020. [].",
          "title": "Generating new concepts with hybrid neuro-symbolic models."
        },
        {
          "children": [],
          "description": "2021. [].",
          "title": "Learning Task-General Representations with Generative Neuro-Symbolic Modeling"
        },
        {
          "children": [],
          "description": "2016. [].",
          "title": "Hybrid computing using a neural network with dynamic external memory"
        },
        {
          "children": [],
          "description": "2019. []. A core challenge for both physics and artificial intelligence (AI) is symbolic regression: finding a symbolic expression that matches data from an unknown function. Although this problem is likely to be NP-hard in principle, functions of practical interest often exhibit symmetries, separability, compositionality, and other simplifying properties. In this spirit, the authors develop a recursive multidimensional symbolic regression algorithm that combines neural network fitting with a suite of physics-inspired techniques. The authors apply it to 100 equations from the Feynman Lectures on Physics, and it discovers all of them, while previous publicly available software cracks only 71; for a more difficult physics-based test set, this work improves the state-of-the-art success rate from 15 to 90%.",
          "title": "AI Feynman: A physics-inspired method for symbolic regression"
        },
        {
          "children": [],
          "description": "2019. [].",
          "title": "Classification-by-Components: Probabilistic Modeling of Reasoning over a Set of Components"
        },
        {
          "children": [],
          "description": "2020. [].",
          "title": "Neuro-Symbolic Visual Reasoning: Disentangling “Visual” from “Reasoning”"
        },
        {
          "children": [],
          "description": "2020. [].",
          "title": "Understanding Deep Architectures with Reasoning Layer"
        },
        {
          "children": [],
          "description": "2020. [].",
          "title": "An Explicitly Relational Neural Network Architecture"
        },
        {
          "children": [],
          "description": "2021. []. Yoshua Bengio's perspective on slot attention model as a general production system.",
          "title": "Neural Production Systems"
        },
        {
          "children": [],
          "description": "2020. [].",
          "title": "Compositional Generalization via Neural-Symbolic Stack Machines"
        },
        {
          "children": [],
          "description": "2019. [].",
          "title": "Stochastic Optimization of Sorting Networks via Continuous Relaxations"
        },
        {
          "children": [],
          "description": "2020. [].",
          "title": "Program Guided Agent"
        },
        {
          "children": [],
          "description": "2020. [].",
          "title": "Learning Compositional Rules via Neural Program Synthesis"
        },
        {
          "children": [],
          "description": "2020. [].",
          "title": "Discovering Symbolic Models from Deep Learning with Inductive Biases"
        },
        {
          "children": [],
          "description": "2019. [].",
          "title": "Neural Logic Machines"
        },
        {
          "children": [],
          "description": "2019. [].",
          "title": "The Neuro-Symbolic Concept Learner: Interpreting Scenes, Words, and Sentences From Natural Supervision"
        },
        {
          "children": [],
          "description": "2019. [].",
          "title": "Visual Concept-Metaconcept Learning"
        },
        {
          "children": [],
          "description": "2021. [].",
          "title": "Grounding Physical Concepts of Objects and Events Through Dynamic Visual Reasoning"
        },
        {
          "children": [],
          "description": "2021. [].",
          "title": "Temporal and Object Quantification Networks"
        },
        {
          "children": [],
          "description": "2021. []. [].",
          "title": "Grounded Language Learning Fast and Slow",
          "repo_info": {
            "archived": false,
            "language": "Python",
            "last_commit": "2021-10-28T13:52:32Z",
            "owner": "deepmind",
            "repo": "dm_fast_mapping",
            "stars": 54
          }
        },
        {
          "children": [],
          "description": "2022. []. A neuro-symbolic framework that integrates meta-policy learning in inductive logic programming.",
          "title": "Detect, Understand, Act: A Neuro-symbolic Hierarchical Reinforcement Learning Framework"
        },
        {
          "children": [],
          "description": "2023. []. VISPROG, a neuro-symbolic approach to solving complex and compositional visual tasks given natural language instructions, using the in-context learning ability of large language models to generate python-like modular programs, which are then executed to get both the solution and a comprehensive and interpretable rationale.",
          "title": "Visual Programming: Compositional Visual Reasoning Without Training"
        },
        {
          "children": [],
          "description": "2020. []. []. In many practical tasks, there are usually two kinds of common information: cheap unlabeled data and domain knowledge in the form of symbols. There are some attempts using one single information source, such as semi-supervised learning and abductive learning. However, there is little work to use these two kinds of information sources at the same time, because it is very difficult to combine symbolic logical representation and numerical model optimization effectively. The learning becomes even more challenging when the domain knowledge is insufficient. This paper presents an attempt-Semi-Supervised ABductive Learning (SS-ABL) framework. In this framework, semi-supervised learning is trained via pseudo labels of unlabeled data generated by abductive learning, and the background knowledge is refined via the label distribution predicted by semi-supervised learning. The above framework can be optimized iteratively and can be naturally interpretable. The effectiveness of the framework has been fully verified in the theft judicial sentencing of real legal documents. In the case of missing sentencing elements and mixed legal rules, the framework is apparently superior to many existing baseline practices, and provides explanatory assistance to judicial sentencing.",
          "title": "Semi-Supervised Abductive Learning and Its Application to Theft Judicial Sentencing"
        }
      ],
      "title": "Neural-Symbolic AI"
    },
    {
      "description": "",
      "items": [],
      "title": "Explainability"
    },
    {
      "description": "",
      "items": [
        {
          "children": [],
          "description": "2018. []. During the 1980s Michie defined Machine Learning in terms of two orthogonal axes of performance: predictive accuracy and comprehensibility of generated hypotheses. Since predictive accuracy was readily measurable and comprehensibility not so, later definitions in the 1990s, such as Mitchell’s, tended to use a one-dimensional approach to Machine Learning based solely on predictive accuracy, ultimately favouring statistical over symbolic Machine Learning approaches. In this paper the authors provide a definition of comprehensibility of hypotheses which can be estimated using human participant trials. The authors present two sets of experiments testing human comprehensibility of logic programs. In the first experiment we test human comprehensibility with and without predicate invention. Results indicate comprehensibility is affected not only by the complexity of the presented program but also by the existence of anonymous predicate symbols. In the second experiment the authors directly test whether any state-of-the-art ILP systems are ultra-strong learners in Michie’s sense, and select the Metagol system for use in humans trials. Results show participants were not able to learn the relational concept on their own from a set of examples but they were able to apply the relational definition provided by the ILP system correctly. This implies the existence of a class of relational concepts which are hard to acquire for humans, though easy to understand given an abstract explanation. The authors believe improved understanding of this class could have potential relevance to contexts involving human learning, teaching and verbal interaction.",
          "title": "Ultra-Strong Machine Learning: comprehensibility of programs learned with ILP"
        },
        {
          "children": [],
          "description": "2021. []. Given the recent successes of Deep Learning in AI there has been increased interest in the role and need for explanations in machine learned theories. A distinct notion in this context is that of Michie’s definition of ultra-strong machine learning (USML). USML is demonstrated by a measurable increase in human performance of a task following provision to the human of a symbolic machine learned theory for task performance. A recent paper demonstrates the beneficial effect of a machine learned logic theory for a classification task, yet no existing work has examined the potential harmfulness of machine’s involvement for human comprehension during learning. This paper investigates the explanatory effects of a machine learned theory in the context of simple two person games and proposes a framework for identifying the harmfulness of machine explanations based on the Cognitive Science literature. The approach involves a cognitive window consisting of two quantifiable bounds and it is supported by empirical evidence collected from human trials. The quantitative and qualitative results indicate that human learning aided by a symbolic machine learned theory which satisfies a cognitive window has achieved significantly higher performance than human self learning. Results also demonstrate that human learning aided by a symbolic machine learned theory that fails to satisfy this window leads to significantly worse performance than unaided human learning.",
          "title": "Beneficial and harmful explanatory machine learning"
        },
        {
          "children": [],
          "description": "2017. []. []. This paper proposes gcForest, a decision tree ensemble approach with performance highly competitive to deep neural networks in a broad range of tasks. In contrast to deep neural networks which require great effort in hyper-parameter tuning, gcForest is much easier to train; even when it is applied to different data across different domains in the experiments, excellent performance can be achieved by almost same settings of hyper-parameters. The training process of gcForest is efficient, and users can control training cost according to computational resource available. The efficiency may be further enhanced because gcForest is naturally apt to parallel implementation. Furthermore, in contrast to deep neural networks which require large-scale training data, gcForest can work well even when there are only small-scale training data.",
          "title": "Deep Forest: Towards An Alternative to Deep Neural Networks",
          "repo_info": {
            "archived": false,
            "language": "Python",
            "last_commit": "2025-09-14T06:31:03Z",
            "owner": "LAMDA-NJU",
            "repo": "Deep-Forest",
            "stars": 961
          }
        },
        {
          "children": [],
          "description": "2021. []. []. Machine learning applications such as finance and medicine demand accurate and justifiable predictions, barring most deep learning methods from use. In response, previous work combines decision trees with deep learning, yielding models that (1) sacrifice interpretability for accuracy or (2) sacrifice accuracy for interpretability. This work forgoes this dilemma by jointly improving accuracy and interpretability using Neural-Backed Decision Trees (NBDTs). NBDTs replace a neural network's final linear layer with a differentiable sequence of decisions and a surrogate loss. This forces the model to learn high-level concepts and lessens reliance on highly-uncertain decisions, yielding (1) accuracy: NBDTs match or outperform modern neural networks on CIFAR, ImageNet and better generalize to unseen classes by up to 16%. Furthermore, the surrogate loss improves the original model's accuracy by up to 2%. NBDTs also afford (2) interpretability: improving human trustby clearly identifying model mistakes and assisting in dataset debugging.",
          "title": "NBDT: Neural-Backed Decision Trees",
          "repo_info": {
            "archived": false,
            "language": "Python",
            "last_commit": "2023-05-01T21:23:52Z",
            "owner": "alvinwan",
            "repo": "neural-backed-decision-trees",
            "stars": 624
          }
        }
      ],
      "title": "Strong Machine Learning"
    },
    {
      "description": "",
      "items": [
        {
          "children": [],
          "description": "2021. Class Activation Map methods implemented in Pytorch, with many elegant features.",
          "title": "pytorch-grad-cam",
          "repo_info": {
            "archived": false,
            "language": "Python",
            "last_commit": "2025-04-07T05:12:45Z",
            "owner": "jacobgil",
            "repo": "pytorch-grad-cam",
            "stars": 12604
          }
        },
        {
          "children": [],
          "description": "2017. []. []. []. The original paper on visualizing the class activation maps to explain convolutional neural networks.",
          "title": "Network dissection: Quantifying interpretability of deep visual representations"
        },
        {
          "children": [],
          "description": "2020. []. David Bau's review on network dissection for discriminative and generative models.",
          "title": "Understanding the role of Individual Units in a Deep Neural Network"
        },
        {
          "children": [],
          "description": "2020. []. A perspective on treating neural networks as circuits.",
          "title": "Zoom In: An Introduction to Circuits"
        },
        {
          "children": [],
          "description": "2020. []. []. A concept-composition version of network dissection.",
          "title": "Compositional Explanations of Neurons",
          "repo_info": {
            "archived": false,
            "language": "HTML",
            "last_commit": "2021-04-09T17:36:01Z",
            "owner": "jayelm",
            "repo": "compexp",
            "stars": 26
          }
        },
        {
          "children": [],
          "description": "2019. [].",
          "title": "This Looks Like That: Deep Learning for Interpretable Image Recognition"
        },
        {
          "children": [],
          "description": "2019. [].",
          "title": "Unsupervised learning by competing hidden units"
        },
        {
          "children": [],
          "description": "2021. []. []. []. A perspective on image background provides strong clue for foreground classification.",
          "title": "Noise or Signal: The Role of Backgrounds in Image Classification",
          "repo_info": {
            "archived": false,
            "language": "Python",
            "last_commit": "2020-10-02T00:15:53Z",
            "owner": "MadryLab",
            "repo": "backgrounds_challenge",
            "stars": 143
          }
        },
        {
          "children": [],
          "description": "2018. []. Maching the learned pattern of neurons in different neural networks.",
          "title": "Towards Understanding Learning Representations: To What Extent Do Different Neural Networks Learn the Same Representation"
        },
        {
          "children": [],
          "description": "2020. [].",
          "title": "Individual differences among deep neural network models"
        }
      ],
      "title": "Explainable Deep Learning"
    },
    {
      "description": "",
      "items": [],
      "title": "Methodologies for Experiments"
    },
    {
      "description": "",
      "items": [],
      "title": "Meta-Level Considerations"
    },
    {
      "description": "",
      "items": [],
      "title": "Science Logology"
    },
    {
      "description": "",
      "items": [
        {
          "children": [],
          "description": "2023. []. A review article that examines breakthroughs over the past decade that include self-supervised learning, which allows models to be trained on vast amounts of unlabelled data, and geometric deep learning, which leverages knowledge about the structure of scientific data to enhance model accuracy and efficiency.",
          "title": "Scientific discovery in the age of artificial intelligence"
        },
        {
          "children": [],
          "description": "2024. []. The development of AI synthesis planners trained solely on reaction-example-data has stagnated and is not on par with the performance of “hybrid” algorithms combining AI with expert knowledge. This Perspective examines possible causes of these shortcomings, extending beyond the established reasoning of insufficient quantities of reaction data. Drawing attention to the intricacies and data biases that are specific to the domain of synthetic chemistry, the authors advocate augmenting the unique capabilities of AI with the knowledge base and the reasoning strategies of domain experts. By actively involving synthetic chemists, who are the end users of any synthesis planning software, into the development process, the authors envision to bridge the gap between computer algorithms and the intricate nature of chemical synthesis.",
          "title": "Artificial Intelligence for Retrosynthetic Planning Needs Both Data and Expert Knowledge"
        },
        {
          "children": [],
          "description": "2023. []. []. A survey on the performance of LLMs within the context of scientific discovery, focusing on GPT-4.",
          "title": "The Impact of Large Language Models on Scientific Discovery: a Preliminary Study using GPT-4",
          "repo_info": {
            "archived": false,
            "language": null,
            "last_commit": "2024-04-11T08:44:22Z",
            "owner": "microsoft",
            "repo": "LLM4ScientificDiscovery",
            "stars": 77
          }
        },
        {
          "children": [],
          "description": "2019. []. In the process of finding high-performance materials for organic photovoltaics (OPVs), it is meaningful if one can establish the relationship between chemical structures and photovoltaic properties even before synthesizing them. This work first establishes a database containing over 1700 donor materials reported in the literature. Through supervised learning, our machine learning (ML) models can build up the structure-property relationship and, thus, implement fast screening of OPV materials. The authors explore several expressions for molecule structures, i.e., images, ASCII strings, descriptors, and fingerprints, as inputs for various ML algorithms. It is found that fingerprints with length over 1000 bits can obtain high prediction accuracy. The reliability of the approach is further verified by screening 10 newly designed donor materials. Good consistency between model predictions and experimental outcomes is obtained. The result indicates that ML is a powerful tool to prescreen new OPV materials, thus accelerating the development of the OPV field.",
          "title": "Machine learning-assisted molecular design and efficiency prediction for high-performance organic photovoltaic materials"
        },
        {
          "children": [],
          "description": "2018. []. The design of novel proteins has many applications but remains an attritional process with success in isolated cases. Meanwhile, deep learning technologies have exploded in popularity in recent years and are increasingly applicable to biology due to the rise in available data. This work attempts to link protein design and deep learning by using variational autoencoders to generate protein sequences conditioned on desired properties. Potential copper and calcium binding sites are added to non-metal binding proteins without human intervention and compared to a hidden Markov model. In another use case, a grammar of protein structures is developed and used to produce sequences for a novel protein topology. One candidate structure is found to be stable by molecular dynamics simulation. The ability of the model to confine the vast search space of protein sequences and to scale easily has the potential to assist in a variety of protein design tasks.",
          "title": "Design of metalloproteins and novel protein folds using variational autoencoders"
        },
        {
          "children": [],
          "description": "2021. []. This paper provides the first computational method that can regularly predict protein structures with atomic accuracy even in cases in which no similar structure is known. This approach is a canonical application of observation- and explanation- based method for protein structure prediction instead of first-principle-based methods.",
          "title": "Highly accurate protein structure prediction with AlphaFold"
        },
        {
          "children": [],
          "description": "2023. []. []. This work studies Bayesian optimization algorithms to investigate how artificial intelligence (AI) might decrease the cost of developing complex semiconductor chip processes. In particular, this work create a controlled virtual process game to systematically benchmark the performance of humans and computers for the design of a semiconductor fabrication process. The authors find that human engineers excel in the early stages of development, whereas the algorithms are far more cost-efficient near the tight tolerances of the target.",
          "title": "Human–machine collaboration for improving semiconductor process development"
        },
        {
          "children": [],
          "description": "2023. []. This paper presents RETFound, a foundation model for retinal images that learns generalizable representations from unlabelled retinal images and provides a basis for label-efficient model adaptation in several applications. Specifically, RETFound is trained on 1.6 million unlabelled retinal images by means of self-supervised learning and then adapted to disease detection tasks with explicit labels.",
          "title": "A foundation model for generalizable disease detection from retinal images"
        },
        {
          "children": [],
          "description": "2023. []. This paer introduces an artificial-intelligence-based method for accurate, medium-range global weather forecasting. It shows that three-dimensional deep networks equipped with Earth-specific priors are effective at dealing with complex patterns in weather data, and that a hierarchical temporal aggregation strategy reduces accumulation errors in medium-range forecasting. Trained on 39 years of global data, the program, Pangu-Weather, obtains stronger deterministic forecast results on reanalysis data in all tested variables when compared with the world’s best NWP system, the operational integrated forecasting system of the European Centre for Medium-Range Weather Forecasts.",
          "title": "Accurate medium-range global weather forecasting with 3D neural networks"
        },
        {
          "children": [],
          "description": "2023. [].",
          "title": "Learning skillful medium-range global weather forecasting"
        },
        {
          "children": [],
          "description": "2023. [].",
          "title": "Skilful nowcasting of extreme precipitation with NowcastNet"
        },
        {
          "children": [],
          "description": "2023. []. An artificial intelligence system driven by GPT-4 that autonomously designs, plans and performs complex experiments by incorporating large language models empowered by tools such as internet and documentation search, code execution and experimental automation.",
          "title": "Autonomous chemical research with large language models"
        },
        {
          "children": [],
          "description": "2023. []. []. This paper introduces ChemCrow, an LLM chemistry agent designed to accomplish tasks across organic synthesis, drug discovery and materials design. By integrating 18 expert-designed tools and using GPT-4 as the LLM, ChemCrow augments the LLM performance in chemistry, and new capabilities emerge. The agent autonomously planned and executed the syntheses of an insect repellent and three organocatalysts and guided the discovery of a novel chromophore.",
          "title": "Augmenting large language models with chemistry tools"
        },
        {
          "children": [],
          "description": "2024. []. The authors envision “AI scientists” as systems capable of skeptical learning and reasoning that empower biomedical research through collaborative agents that integrate AI models and biomedical tools with experimental platforms. Rather than taking humans out of the discovery process, biomedical AI agents combine human creativity and expertise with AI’s ability to analyze large datasets, navigate hypothesis spaces, and execute repetitive tasks. AI agents are poised to be proficient in various tasks, planning discovery workflows and performing self-assessment to identify and mitigate gaps in their knowledge. These agents use large language models and generative models to feature structured memory for continual learning and use machine learning tools to incorporate scientific knowledge, biological principles, and theories. AI agents can impact areas ranging from virtual cell simulation, programmable control of phenotypes, and the design of cellular circuits to developing new therapies.",
          "title": "Empowering biomedical discovery with AI agents"
        },
        {
          "children": [],
          "description": "2025. []. []. Functional proteomics provides critical insights into cancer mechanisms, facilitating the discovery of novel biomarkers and therapeutic targets. The authors have developed a comprehensive cancer functional proteomics resource using reverse phase protein arrays, incorporating data from nearly 8000 patient samples from The Cancer Genome Atlas and approximately 900 samples from the Cancer Cell Line Encyclopedia. The dataset includes a curated panel of nearly 500 high-quality antibodies, covering all major cancer hallmark pathways. To enhance the accessibility and analytic power of this resource, this work introduces DrBioRight 2.0, an intuitive bioinformatic platform powered by state-of-the-art large language models. DrBioRight enables researchers to explore protein-centric cancer omics data, perform advanced analyses, visualize results, and engage in interactive discussions using natural language. By streamlining complex proteogenomic analyses, this tool accelerates the translation of large-scale functional proteomics data into meaningful biomedical insights.",
          "title": "DrBioRight 2.0: an LLM-powered bioinformatics chatbot for large-scale cancer functional proteomics analysis"
        },
        {
          "children": [],
          "description": "2025. []. Science frequently benefits from teams of interdisciplinary researchers, but many scientists do not have easy access to experts from multiple fields. Although large language models (LLMs) have shown an impressive ability to aid researchers across diverse domains, their uses have been largely limited to answering specific scientific questions rather than performing open-ended research. Here the authors expand the capabilities of LLMs for science by introducing the Virtual Lab, an artificial intelligence (AI)–human research collaboration to perform sophisticated, interdisciplinary science research. The Virtual Lab consists of an LLM Principal Investigator agent guiding a team of LLM scientist agents through a series of research meetings, with a human researcher providing high-level feedback. The authors applied the Virtual Lab to design nanobody binders to recent variants of SARS-CoV-2. The Virtual Lab created a novel computational nanobody design pipeline that incorporates the protein language model ESM, the protein folding model AlphaFold-Multimer and the computational biology software Rosetta and designed 92 new nanobodies. Experimental validation reveals a range of functional nanobodies with promising binding profiles across SARS-CoV-2 variants. In particular, two new nanobodies exhibit improved binding to the recent JN.1 or KP.3 variants while maintaining strong binding to the ancestral viral spike protein, suggesting that these are suitable candidates for further investigation. This work demonstrates how the Virtual Lab can rapidly make an impactful, real-world scientific discovery.",
          "title": "The Virtual Lab of AI agents designs new SARS-CoV-2 nanobodies"
        },
        {
          "children": [],
          "description": "2023. []. []. This paper presents an automatic evaluation framework for the task of planning experimental protocols, and introduces BioProt: a dataset of biology protocols with corresponding pseudocode representations.",
          "title": "BioPlanner: Automatic Evaluation of LLMs on Protocol Planning in Biology",
          "repo_info": {
            "archived": false,
            "language": "Python",
            "last_commit": "2024-07-05T19:12:54Z",
            "owner": "bioplanner",
            "repo": "bioplanner",
            "stars": 27
          }
        },
        {
          "children": [],
          "description": "2025. []. Conventional biomedical research is increasingly labor-intensive due to the exponential growth of scientific literature and datasets. Artificial intelligence (AI), particularly large language models (LLMs), has the potential to revolutionize this process by automating various steps. Still, significant challenges remain, including the need for multidisciplinary expertise, logicality of experimental design, and performance measurements. This paper introduces BioResearcher, the first end-to-end automated system designed to streamline the entire biomedical research process involving dry lab experiments. BioResearcher employs a modular multi-agent architecture, integrating specialized agents for search, literature processing, experimental design, and programming. By decomposing complex tasks into logically related sub-tasks and utilizing a hierarchical learning approach, BioResearcher effectively addresses the challenges of multidisciplinary requirements and logical complexity. Furthermore, BioResearcher incorporates an LLM-based reviewer for in-process quality control and introduces novel evaluation metrics to assess the quality and automation of experimental protocols. BioResearcher successfully achieves an average execution success rate of 63.07% across eight previously unmet research objectives. The generated protocols, on average, outperform typical agent systems by 22.0% on five quality metrics. The system demonstrates significant potential to reduce researchers’ workloads and accelerate biomedical discoveries, paving the way for future innovations in automated research systems.",
          "title": "From intention to implementation: automating biomedical research via LLMs"
        },
        {
          "children": [],
          "description": "2024. []. Autonomous reaction network exploration algorithms offer a systematic approach to explore mechanisms of complex chemical processes. However, the resulting reaction networks are so vast that an exploration of all potentially accessible intermediates is computationally too demanding. This paper introduces a STEERING WHEEL to guide an otherwise unbiased automated exploration. The STEERING WHEEL algorithm is intuitive, generally applicable, and enables one to focus on specific regions of an emerging network. It also allows for guiding automated data generation in the context of mechanism exploration, catalyst design, and other chemical optimization challenges.",
          "title": "A human-machine interface for automatic exploration of chemical reaction networks"
        },
        {
          "children": [],
          "description": "2025. []. Anode-free or ‘zero-excess’ lithium metal batteries offer high energy density compared to current lithium-ion batteries but require electrolyte innovation to extend cycle life. Due to the lack of universal design principles, electrolyte development for anode-free lithium metal batteries is slow and incremental and mainly driven by trial-and-error. This work demonstrates the use of active learning as an alternative approach to accelerate electrolyte discovery for anode-free lithium metal batteries. Unlike conventional data-intensive frequentist machine learning techniques, the active learning framework employs sequential Bayesian experimental design with Bayesian model averaging to efficiently identify optimal candidates in typical data-scarce and noisy label settings. Using capacity retention in real Cu||LiFePO4 cells as the target property, the approach integrates experimental feedback to iteratively refine predictions. Starting with just 58 data points from an in-house cycling dataset, the active learning framework explored a virtual search space of 1 million electrolytes, rapidly converging on optimal candidates. After seven active learning campaigns with about ten electrolytes tested in each, four distinct electrolyte solvents are identified that rival state-of-the-art electrolytes in performance. This work showcases the promise of active learning approaches in navigating large electrolyte chemical spaces for next-generation batteries.",
          "title": "Active learning accelerates electrolyte solvent screening for anode-free lithium metal batteries"
        },
        {
          "children": [],
          "description": "2024. []. The automatic analysis of patent publications has potential to accelerate research across various domains, including drug discovery and material science. Within patent documents, crucial information often resides in visual depictions of molecule structures. PatCID (Patent-extracted Chemical-structure Images database for Discovery) allows to access such information at scale. It enables users to search which molecules are displayed in which documents. PatCID contains 81M chemical-structure images and 14M unique chemical structures. This work compares PatCID with state-of-the-art chemical patent-databases. On a random set, PatCID retrieves 56.0% of molecules, which is higher than automatically-created databases, Google Patents (41.5%) and SureChEMBL (23.5%), as well as manually-created databases, Reaxys (53.5%) and SciFinder (49.5%). Leveraging state-of-the-art methods of document understanding, PatCID high-quality data outperforms currently available automatically-generated patent-databases. PatCID even competes with proprietary manually-created patent-databases. This enables promising applications for automatic literature review and learning-based molecular generation methods.",
          "title": "PatCID: an open-access dataset of chemical structures in patent documents"
        },
        {
          "children": [],
          "description": "2025. []. Large language models (LLMs) are a form of artificial intelligence system encapsulating vast knowledge in the form of natural language. These systems are adept at numerous complex tasks including creative writing, storytelling, translation, question-answering, summarization and computer code generation. Although LLMs have seen initial applications in natural sciences, their potential for driving scientific discovery remains largely unexplored. This work introduces LLM4SD, a framework designed to harness LLMs for driving scientific discovery in molecular property prediction by synthesizing knowledge from literature and inferring knowledge from scientific data. LLMs synthesize knowledge by extracting established information from scientific literature, such as molecular weight being key to predicting solubility. For inference, LLMs identify patterns in molecular data, particularly in Simplified Molecular Input Line Entry System-encoded structures, such as halogen-containing molecules being more likely to cross the blood–brain barrier. This information is presented as interpretable knowledge, enabling the transformation of molecules into feature vectors. By using these features with interpretable models such as random forest, LLM4SD can outperform the current state of the art across a range of benchmark tasks for predicting molecular properties. The authors foresee it providing interpretable and potentially new insights, aiding scientific discovery in molecular property prediction.",
          "title": "Large language models for scientific discovery in molecular property prediction"
        },
        {
          "children": [],
          "description": "2023. []. Retrosynthesis planning, the process of identifying a set of available reactions to synthesize the target molecules, remains a major challenge in organic synthesis. Recently, computer-aided synthesis planning has gained renewed interest and various retrosynthesis prediction algorithms based on deep learning have been proposed. However, most existing methods are limited to the applicability and interpretability of model predictions, and further improvement of predictive accuracy to a more practical level is still required. In this work, inspired by the arrow-pushing formalism in chemical reaction mechanisms, the authors present an end-to-end architecture for retrosynthesis prediction called Graph2Edits. Specifically, Graph2Edits is based on graph neural network to predict the edits of the product graph in an auto-regressive manner, and sequentially generates transformation intermediates and final reactants according to the predicted edits sequence. This strategy combines the two-stage processes of semi-template-based methods into one-pot learning, improving the applicability in some complicated reactions, and also making its predictions more interpretable. Evaluated on the standard benchmark dataset USPTO-50k, the model achieves the state-of-the-art performance for semi-template-based retrosynthesis with a promising 55.1% top-1 accuracy.",
          "title": "Retrosynthesis prediction using an end-to-end graph generative architecture for molecular graph editing"
        },
        {
          "children": [],
          "description": "2023. []. ChipNeMo aims to explore the applications of large language models (LLMs) for industrial chip design. Instead of directly deploying off-the-shelf commercial or open-source LLMs, the authors instead adopt the following domain adaptation techniques: domain-adaptive tokenization, domain-adaptive continued pretraining, model alignment with domain-specific instructions, and domain-adapted retrieval models. The authors evaluate these methods on three selected LLM applications for chip design: an engineering assistant chatbot, EDA script generation, and bug summarization and analysis. Evaluations demonstrate that domain-adaptive pretraining of language models, can lead to superior performance in domain related downstream tasks compared to their base LLaMA2 counterparts, without degradations in generic capabilities. In particular, the largest model, ChipNeMo-70B, outperforms the highly capable GPT-4 on two of the use cases, namely engineering assistant chatbot and EDA scripts generation, while exhibiting competitive performance on bug summarization and analysis. These results underscore the potential of domain-specific customization for enhancing the effectiveness of large language models in specialized applications.",
          "title": "ChipNeMo: Domain-Adapted LLMs for Chip Design"
        },
        {
          "children": [],
          "description": "2021. []. This paper addresses the problem of new Single-atom-alloy catalysts (SAACs) discovery by applying a compressed-sensing data-analytics approach parameterized with density-functional inputs.",
          "title": "Single-atom alloy catalysts designed by first-principles calculations and artificial intelligence"
        },
        {
          "children": [],
          "description": "2021. [].",
          "title": "Biological structure and function emerge from scaling unsupervised learning to 250 million protein sequences"
        },
        {
          "children": [],
          "description": "2016. [].",
          "title": "Comparability of automated human induced pluripotent stem cell culture: a pilot study"
        },
        {
          "children": [],
          "description": "2021. []. 3D visualization technologies such as virtual reality (VR), augmented reality (AR), and mixed reality (MR) have gained popularity in the recent decade. Digital extended reality (XR) technologies have been adopted in various domains ranging from entertainment to education because of their accessibility and affordability. XR modalities create an immersive experience, enabling 3D visualization of the content without a conventional 2D display constraint. This paper provides a perspective on XR in current biomedical applications and demonstrate case studies using cell biology concepts, multiplexed proteomics images, surgical data for heart operations, and cardiac 3D models. Emerging challenges associated with XR technologies in the context of adverse health effects and a cost comparison of distinct platforms are discussed. The presented XR platforms will be useful for biomedical education, medical training, surgical guidance, and molecular data visualization to enhance trainees’ and students’ learning, medical operation accuracy, and the comprehensibility of complex biological systems.",
          "title": "Virtual and augmented reality for biomedical applications"
        },
        {
          "children": [],
          "description": "2019. []. The microscopic assessment of tissue samples is instrumental for the diagnosis and staging of cancer, and thus guides therapy. However, these assessments demonstrate considerable variability and many regions of the world lack access to trained pathologists. Though artificial intelligence (AI) promises to improve the access and quality of healthcare, the costs of image digitization in pathology and difficulties in deploying AI solutions remain as barriers to real-world use. This work proposes a cost-effective solution: the augmented reality microscope (ARM). The ARM overlays AI-based information onto the current view of the sample in real time, enabling seamless integration of AI into routine workflows.",
          "title": "An augmented reality microscope with real-time artificial intelligence integration for cancer diagnosis"
        },
        {
          "children": [],
          "description": "2023. [].",
          "title": "Optimizing Spaced Repetition Schedule by Capturing the Dynamics of Memory"
        },
        {
          "children": [],
          "description": "2020. []. Generating answers to legal questions, analyze contracts, and summarizing legal documents, making legal knowledge more accessible to non-experts.",
          "title": "LEGAL-BERT: The Muppets straight out of Law School"
        },
        {
          "children": [],
          "description": "2020. []. Answering medical questions, identifying relevant clinical trials, and diagnosing diseases based on symptoms, making medical information more accessible to the general public.",
          "title": "BioBERT: a pre-trained biomedical language representation model for biomedical text mining"
        },
        {
          "children": [],
          "description": "2020. []. Predicting stock market trends, analyzing financial documents, and generating summaries of economic news articles, helping to disseminate financial knowledge.",
          "title": "Finbert: A pre-trained financial language representation model for financial text mining"
        },
        {
          "children": [],
          "description": "2019. []. Searching and synthesizing scientific literature, aiding researchers in hypothesis generation, and assisting with experimental design, making scientific knowledge more accessible.",
          "title": "SciBERT: A Pretrained Language Model for Scientific Text"
        },
        {
          "children": [],
          "description": "2020. []. Completing code, generating programming documentation, and providing technical support, making programming knowledge more accessible to non-experts.",
          "title": "CodeBERT: A Pre-Trained Model for Programming and Natural Languages"
        }
      ],
      "title": "AI Assisted Research"
    },
    {
      "description": "",
      "items": [],
      "title": "Commonsense"
    },
    {
      "description": "",
      "items": [],
      "title": "Academic Tools"
    },
    {
      "description": "",
      "items": [],
      "title": "Institute & Researcher"
    },
    {
      "description": "",
      "items": [],
      "title": "People & Book"
    },
    {
      "description": "The initiator of this repo has been struggling to taxonomize related topics, since there are so many perspectives to follow, such as task-oriented, technique-oriented, and metaphysics-oriented. Finally he decided to focus on the perspective of The Sciences of Intelligence---each topic describes a phenomenon of intelligence, or an intelligent behavior---they show the objectives of reverse-engineering human intelligence for computational methods. These topics are never restricted to specific technical methods or tasks, but are trying to organize the nature of intelligence---from both the software perspective and the hardware perspective.\nObviously, this reading list is far from covering the every aspect of AGI and CoCoSci. Since the list is a by-product of the literature reviews when the initiator is working on Abduction and Bayesian modeling, other topics are also collected with biases, more or less. Abduction may be the way humans explain the world with the known, and discover the unknown, requiring much more investigations into its computational basis, cognitive underpinnings, and applications to AI. Please feel free to reach out!\n*Back to Top",
      "items": [],
      "title": "About"
    }
  ],
  "metadata": {
    "last_updated": "2026-02-12T04:28:16.918Z",
    "original_repository": "YuzheSHI/awesome-agi-cocosci",
    "source_repository": "v1nvn/enhansome-agi-cocosci",
    "source_repository_description": null,
    "title": "Awesome Artificial General Intelligence and Computational Cognitive Sciences with stars"
  }
}